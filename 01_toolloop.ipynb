{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp toolloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Tool loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322371c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['ANTHROPIC_LOG'] = 'debug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from claudette.core import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "from anthropic.types import TextBlock, Message, ToolUseBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63111054",
   "metadata": {},
   "source": [
    "Anthropic provides an [interesting example](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/customer_service_agent.ipynb) of using tools to mock up a hypothetical ordering system. We're going to take it a step further, and show how we can dramatically simplify the process, whilst completing more complex tasks.\n",
    "\n",
    "We'll start by defining the same mock customer/order data as in Anthropic's example, plus create a entity relationship between customers and orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {\n",
    "    \"O1\": dict(id=\"O1\", product=\"Widget A\", quantity=2, price=19.99, status=\"Shipped\"),\n",
    "    \"O2\": dict(id=\"O2\", product=\"Gadget B\", quantity=1, price=49.99, status=\"Processing\"),\n",
    "    \"O3\": dict(id=\"O3\", product=\"Gadget B\", quantity=2, price=49.99, status=\"Shipped\")}\n",
    "\n",
    "customers = {\n",
    "    \"C1\": dict(name=\"John Doe\", email=\"john@example.com\", phone=\"123-456-7890\",\n",
    "               orders=[orders['O1'], orders['O2']]),\n",
    "    \"C2\": dict(name=\"Jane Smith\", email=\"jane@example.com\", phone=\"987-654-3210\",\n",
    "               orders=[orders['O3']])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8eed7b",
   "metadata": {},
   "source": [
    "We can now define the same functions from the original example -- but note that we don't need to manually create the large JSON schema, since Claudette handles all that for us automatically from the functions directly. We'll add some extra functionality to update order details when cancelling too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info(\n",
    "    customer_id:str # ID of the customer\n",
    "): # Customer's name, email, phone number, and list of orders\n",
    "    \"Retrieves a customer's information and their orders based on the customer ID\"\n",
    "    print(f'- Retrieving customer {customer_id}')\n",
    "    return customers.get(customer_id, \"Customer not found\")\n",
    "\n",
    "def get_order_details(\n",
    "    order_id:str # ID of the order\n",
    "): # Order's ID, product name, quantity, price, and order status\n",
    "    \"Retrieves the details of a specific order based on the order ID\"\n",
    "    print(f'- Retrieving order {order_id}')\n",
    "    return orders.get(order_id, \"Order not found\")\n",
    "\n",
    "def cancel_order(\n",
    "    order_id:str # ID of the order to cancel\n",
    ")->bool: # True if the cancellation is successful\n",
    "    \"Cancels an order based on the provided order ID\"\n",
    "    print(f'- Cancelling order {order_id}')\n",
    "    if order_id not in orders: return False\n",
    "    orders[order_id]['status'] = 'Cancelled'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1278535",
   "metadata": {},
   "source": [
    "We're now ready to start our chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4231dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_customer_info, get_order_details, cancel_order]\n",
    "chat = Chat(model, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db970a",
   "metadata": {},
   "source": [
    "We'll start with the same request as Anthropic showed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n",
      "tool_use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ToolUseBlock(id='toolu_0168sUZoEUpjzk5Y8WN3q9XL', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat('Can you tell me the email address for customer C1?')\n",
    "print(r.stop_reason)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d3ae8",
   "metadata": {},
   "source": [
    "Claude asks us to use a tool. Claudette handles that automatically by just calling it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09196e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The email address for customer C1 is john@example.com.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat()\n",
    "contents(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe5edb",
   "metadata": {},
   "source": [
    "Let's consider a more complex case than in the original example -- what happens if a customer wants to cancel all of their orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa531d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n",
      "tool_use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextBlock(text=\"Okay, let's cancel all orders for customer C1:\", type='text'),\n",
       " ToolUseBlock(id='toolu_01ADr1rEp7NLZ2iKWfLp7vz7', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "r = chat('Please cancel all orders for customer C1 for me.')\n",
    "print(r.stop_reason)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2432a1",
   "metadata": {},
   "source": [
    "This is the start of a multi-stage tool use process. Doing it manually step by step is inconvenient, so let's write a function to handle this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Chat.__call__)\n",
    "def toolloop(self:Chat,\n",
    "             pr, # Prompt to pass to Claude\n",
    "             max_steps=10, # Maximum number of tool requests to loop through\n",
    "             trace_func:Optional[callable]=None, # Function to trace tool use steps (e.g `print`)\n",
    "             cont_func:Optional[callable]=noop, # Function that stops loop if returns False\n",
    "             **kwargs):\n",
    "    \"Add prompt `pr` to dialog and get a response from Claude, automatically following up with `tool_use` messages\"\n",
    "    n_msgs = len(self.h)\n",
    "    r = self(pr, **kwargs)\n",
    "    for i in range(max_steps):\n",
    "        if r.stop_reason!='tool_use': break\n",
    "        if trace_func: trace_func(self.h[n_msgs:]); n_msgs = len(self.h)\n",
    "        r = self(**kwargs)\n",
    "        if not (cont_func or noop)(self.h[-2]): break\n",
    "    if trace_func: trace_func(self.h[n_msgs:])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a0859",
   "metadata": {},
   "source": [
    "We'll start by re-running our previous request - we shouldn't have to manually pass back the `tool_use` message any more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa6634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The email address for customer C1 is john@example.com.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01Fm2CY76dNeWief4kUW6r71`\n",
       "- content: `[{'text': 'The email address for customer C1 is john@example.com.', 'type': 'text'}]`\n",
       "- model: `claude-3-haiku-20240307`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 720, 'output_tokens': 19, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01Fm2CY76dNeWief4kUW6r71', content=[TextBlock(text='The email address for customer C1 is john@example.com.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 720; Out: 19; Cache create: 0; Cache read: 0; Total: 739)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "r = chat.toolloop('Can you tell me the email address for customer C1?')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6131f0",
   "metadata": {},
   "source": [
    "Let's see if it can handle the multi-stage process now -- we'll add `trace_func=print` to see each stage of the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d3eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Please cancel all orders for customer C1 for me.'}]}, {'role': 'assistant', 'content': [TextBlock(text=\"Okay, let's cancel all orders for customer C1:\", type='text'), ToolUseBlock(id='toolu_01SvivKytaRHEdKixEY9dUDz', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]}, {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01SvivKytaRHEdKixEY9dUDz', 'content': \"{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Shipped'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}]}\"}]}]\n",
      "- Cancelling order O1\n",
      "[{'role': 'assistant', 'content': [TextBlock(text=\"Based on the customer information, it looks like there are 2 orders for customer C1:\\n- Order O1 for Widget A\\n- Order O2 for Gadget B\\n\\nLet's cancel each of these orders:\", type='text'), ToolUseBlock(id='toolu_01DoGVUPVBeDYERMePHDzUoT', input={'order_id': 'O1'}, name='cancel_order', type='tool_use')]}, {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01DoGVUPVBeDYERMePHDzUoT', 'content': 'True'}]}]\n",
      "- Cancelling order O2\n",
      "[{'role': 'assistant', 'content': [ToolUseBlock(id='toolu_01XNwS35yY88Mvx4B3QqDeXX', input={'order_id': 'O2'}, name='cancel_order', type='tool_use')]}, {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01XNwS35yY88Mvx4B3QqDeXX', 'content': 'True'}]}]\n",
      "[{'role': 'assistant', 'content': [TextBlock(text=\"I've successfully cancelled both orders O1 and O2 for customer C1. Please let me know if you need anything else!\", type='text')]}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I've successfully cancelled both orders O1 and O2 for customer C1. Please let me know if you need anything else!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01K1QpUZ8nrBVUHYTrH5QjSF`\n",
       "- content: `[{'text': \"I've successfully cancelled both orders O1 and O2 for customer C1. Please let me know if you need anything else!\", 'type': 'text'}]`\n",
       "- model: `claude-3-haiku-20240307`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 921, 'output_tokens': 32, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01K1QpUZ8nrBVUHYTrH5QjSF', content=[TextBlock(text=\"I've successfully cancelled both orders O1 and O2 for customer C1. Please let me know if you need anything else!\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 921; Out: 32; Cache create: 0; Cache read: 0; Total: 953)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "r = chat.toolloop('Please cancel all orders for customer C1 for me.', trace_func=print)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8c9fc",
   "metadata": {},
   "source": [
    "OK Claude thinks the orders were cancelled -- let's check one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving order O2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The status of order O2 is now 'Cancelled' since I successfully cancelled that order earlier.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01XcXpFDwoZ3u1bFDf5mY8x1`\n",
       "- content: `[{'text': \"The status of order O2 is now 'Cancelled' since I successfully cancelled that order earlier.\", 'type': 'text'}]`\n",
       "- model: `claude-3-haiku-20240307`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 1092, 'output_tokens': 26, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01XcXpFDwoZ3u1bFDf5mY8x1', content=[TextBlock(text=\"The status of order O2 is now 'Cancelled' since I successfully cancelled that order earlier.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1092; Out: 26; Cache create: 0; Cache read: 0; Total: 1118)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop('What is the status of order O2?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a93494",
   "metadata": {},
   "source": [
    "## Code interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04effc",
   "metadata": {},
   "source": [
    "Here is an example of using `toolloop` to implement a simple code interpreter with additional tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aeee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolslm.shell import get_shell\n",
    "from fastcore.meta import delegates\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d565a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class CodeChat(Chat):\n",
    "    imps = 'os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses'\n",
    "    def __init__(self, model: Optional[str] = None, ask:bool=True, **kwargs):\n",
    "        super().__init__(model=model, **kwargs)\n",
    "        self.ask = ask\n",
    "        self.tools.append(self.run_cell)\n",
    "        self.shell = get_shell()\n",
    "        self.shell.run_cell('import '+self.imps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a94f7",
   "metadata": {},
   "source": [
    "We have one additional parameter to creating a `CodeChat` beyond what we pass to `Chat`, which is `ask` -- if that's `True`, we'll prompt the user before running code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def run_cell(\n",
    "    self:CodeChat,\n",
    "    code:str,   # Code to execute in persistent IPython session\n",
    "): # Result of expression on last line (if exists); '#DECLINED#' if user declines request to execute\n",
    "    \"Asks user for permission, and if provided, executes python `code` using persistent IPython session.\"\n",
    "    confirm = f'Press Enter to execute, or enter \"n\" to skip?\\n```\\n{code}\\n```\\n'\n",
    "    if self.ask and input(confirm): return '#DECLINED#'\n",
    "    try: res = self.shell.run_cell(code)\n",
    "    except Exception as e: return traceback.format_exc()\n",
    "    return res.stdout if res.result is None else res.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8425cc8",
   "metadata": {},
   "source": [
    "We just pass along requests to run code to the shell's implementation. Claude often prints results instead of just using the last expression, so we capture stdout in those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f6dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = f'''You are a knowledgable assistant. Do not use tools unless needed.\n",
    "Don't do complex calculations yourself -- use code for them.\n",
    "The following modules are pre-imported for `run_cell` automatically:\n",
    "\n",
    "{CodeChat.imps}\n",
    "\n",
    "Never mention what tools you are using. Note that `run_cell` interpreter state is *persistent* across calls.\n",
    "\n",
    "If a tool returns `#DECLINED#` report to the user that the attempt was declined and no further progress can be made.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(ignored:str='' # Unused parameter\n",
    "            ): # Username of current user\n",
    "    \"Get the username of the user running this session\"\n",
    "    print(\"Looking up username\")\n",
    "    return 'Jeremy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf964f57",
   "metadata": {},
   "source": [
    "In order to test out multi-stage tool use, we create a mock function that Claude can call to get the current username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f875f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = CodeChat(model, tools=[get_user], sp=sp, ask=True, temp=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad0a88",
   "metadata": {},
   "source": [
    "Claude gets confused sometimes about how tools work, so we use examples to remind it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.h = [\n",
    "    'Calculate the square root of `10332`', 'math.sqrt(10332)',\n",
    "    '#DECLINED#', 'I am sorry but the request to execute that was declined and no further progress can be made.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92d000",
   "metadata": {},
   "source": [
    "Providing a callable to toolloop's `trace_func` lets us print out information during the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cde39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_cts(h):\n",
    "    for r in h:\n",
    "        for o in r.get('content'):\n",
    "            if hasattr(o,'text'): print(o.text)\n",
    "            nm = getattr(o, 'name', None)\n",
    "            if nm=='run_cell': print(o.input['code'])\n",
    "            elif nm: print(f'{o.name}({o.input})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2c6c8",
   "metadata": {},
   "source": [
    "...and toolloop's `cont_func` callable let's us provide a function which, if it returns `False`, stops the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cont_decline(c):\n",
    "    return nested_idx(c, 'content', 'content') != '#DECLINED#'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb021f",
   "metadata": {},
   "source": [
    "Now we can try our code interpreter. We start by asking for a function to be created, which we'll use in the next prompt to test that the interpreter is persistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1974763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "checksum = lambda s: functools.reduce(lambda x, y: x * ord(y), s, 1)\n",
      "```\n",
      "\n",
      "Create a 1-line function `checksum` for a string `s`,\n",
      "that multiplies together the ascii values of each character in `s` using `reduce`.\n",
      "Let me help you create that function using `reduce` and `functools`.\n",
      "checksum = lambda s: functools.reduce(lambda x, y: x * ord(y), s, 1)\n",
      "The function has been created. Let me explain how it works:\n",
      "1. It takes a string `s` as input\n",
      "2. Uses `functools.reduce` to multiply together all ASCII values\n",
      "3. `ord(y)` gets the ASCII value of each character\n",
      "4. The initial value is 1 (the third parameter to reduce)\n",
      "5. The lambda function multiplies the accumulator (x) with each new ASCII value\n",
      "\n",
      "You can test it with any string. For example, you could try `checksum(\"hello\")` to see it in action.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The function has been created. Let me explain how it works:\n",
       "1. It takes a string `s` as input\n",
       "2. Uses `functools.reduce` to multiply together all ASCII values\n",
       "3. `ord(y)` gets the ASCII value of each character\n",
       "4. The initial value is 1 (the third parameter to reduce)\n",
       "5. The lambda function multiplies the accumulator (x) with each new ASCII value\n",
       "\n",
       "You can test it with any string. For example, you could try `checksum(\"hello\")` to see it in action.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_011pcGY9LbYqvRSfDPgCqUkT`\n",
       "- content: `[{'text': 'The function has been created. Let me explain how it works:\\n1. It takes a string `s` as input\\n2. Uses `functools.reduce` to multiply together all ASCII values\\n3. `ord(y)` gets the ASCII value of each character\\n4. The initial value is 1 (the third parameter to reduce)\\n5. The lambda function multiplies the accumulator (x) with each new ASCII value\\n\\nYou can test it with any string. For example, you could try `checksum(\"hello\")` to see it in action.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 824, 'output_tokens': 125, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_011pcGY9LbYqvRSfDPgCqUkT', content=[TextBlock(text='The function has been created. Let me explain how it works:\\n1. It takes a string `s` as input\\n2. Uses `functools.reduce` to multiply together all ASCII values\\n3. `ord(y)` gets the ASCII value of each character\\n4. The initial value is 1 (the third parameter to reduce)\\n5. The lambda function multiplies the accumulator (x) with each new ASCII value\\n\\nYou can test it with any string. For example, you could try `checksum(\"hello\")` to see it in action.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 824; Out: 125; Cache create: 0; Cache read: 0; Total: 949)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = '''Create a 1-line function `checksum` for a string `s`,\n",
    "that multiplies together the ascii values of each character in `s` using `reduce`.'''\n",
    "chat.toolloop(pr, temp=0.2, trace_func=_show_cts, cont_func=_cont_decline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100eac7b",
   "metadata": {},
   "source": [
    "By asking for a calculation to be done on the username, we force it to use multiple steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c381e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up username\n",
      "Use it to get the checksum of the username of this session.\n",
      "I'll first get the username using `get_user` and then apply our `checksum` function to it.\n",
      "get_user({'ignored': ''})\n",
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "print(checksum(\"Jeremy\"))\n",
      "```\n",
      "\n",
      "Now I'll calculate the checksum of \"Jeremy\":\n",
      "print(checksum(\"Jeremy\"))\n",
      "The checksum of the username \"Jeremy\" is 1134987783204. This was calculated by multiplying together the ASCII values of each character in \"Jeremy\".\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The checksum of the username \"Jeremy\" is 1134987783204. This was calculated by multiplying together the ASCII values of each character in \"Jeremy\".\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01UXvtcLzzykZpnQUT35v4uD`\n",
       "- content: `[{'text': 'The checksum of the username \"Jeremy\" is 1134987783204. This was calculated by multiplying together the ASCII values of each character in \"Jeremy\".', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 1143, 'output_tokens': 38, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01UXvtcLzzykZpnQUT35v4uD', content=[TextBlock(text='The checksum of the username \"Jeremy\" is 1134987783204. This was calculated by multiplying together the ASCII values of each character in \"Jeremy\".', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1143; Out: 38; Cache create: 0; Cache read: 0; Total: 1181)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = 'Use it to get the checksum of the username of this session.'\n",
    "chat.toolloop(pr, trace_func=_show_cts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefe903",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627b799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
