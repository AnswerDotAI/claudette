{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp toolloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Tool loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from claudette.core import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63111054",
   "metadata": {},
   "source": [
    "Anthropic provides an [interesting example](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/customer_service_agent.ipynb) of using tools to mock up a hypothetical ordering system. We're going to take it a step further, and show how we can dramatically simplify the process, whilst completing more complex tasks.\n",
    "\n",
    "We'll start by defining the same mock customer/order data as in Anthropic's example, plus create a entity relationship between customers and orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {\n",
    "    \"O1\": dict(id=\"O1\", product=\"Widget A\", quantity=2, price=19.99, status=\"Shipped\"),\n",
    "    \"O2\": dict(id=\"O2\", product=\"Gadget B\", quantity=1, price=49.99, status=\"Processing\"),\n",
    "    \"O3\": dict(id=\"O3\", product=\"Gadget B\", quantity=2, price=49.99, status=\"Shipped\")}\n",
    "\n",
    "customers = {\n",
    "    \"C1\": dict(name=\"John Doe\", email=\"john@example.com\", phone=\"123-456-7890\",\n",
    "               orders=[orders['O1'], orders['O2']]),\n",
    "    \"C2\": dict(name=\"Jane Smith\", email=\"jane@example.com\", phone=\"987-654-3210\",\n",
    "               orders=[orders['O3']])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8eed7b",
   "metadata": {},
   "source": [
    "We can now define the same functions from the original example -- but note that we don't need to manually create the large JSON schema, since Claudette handles all that for us automatically from the functions directly. We'll add some extra functionality to update order details when cancelling too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info(\n",
    "    customer_id:str # ID of the customer\n",
    "): # Customer's name, email, phone number, and list of orders\n",
    "    \"Retrieves a customer's information and their orders based on the customer ID\"\n",
    "    print(f'- Retrieving customer {customer_id}')\n",
    "    return customers.get(customer_id, \"Customer not found\")\n",
    "\n",
    "def get_order_details(\n",
    "    order_id:str # ID of the order\n",
    "): # Order's ID, product name, quantity, price, and order status\n",
    "    \"Retrieves the details of a specific order based on the order ID\"\n",
    "    print(f'- Retrieving order {order_id}')\n",
    "    return orders.get(order_id, \"Order not found\")\n",
    "\n",
    "def cancel_order(\n",
    "    order_id:str # ID of the order to cancel\n",
    ")->bool: # True if the cancellation is successful\n",
    "    \"Cancels an order based on the provided order ID\"\n",
    "    print(f'- Cancelling order {order_id}')\n",
    "    if order_id not in orders: return False\n",
    "    orders[order_id]['status'] = 'Cancelled'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1278535",
   "metadata": {},
   "source": [
    "We're now ready to start our chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4231dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_customer_info, get_order_details, cancel_order]\n",
    "chat = Chat(models[-1], tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db970a",
   "metadata": {},
   "source": [
    "We'll start with the same request as Anthropic showed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ToolUseBlock(id='toolu_01BowYG53gJWTWCYC39oWnCj', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat('Can you tell me the email address for customer C1?')\n",
    "print(r.stop_reason)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d3ae8",
   "metadata": {},
   "source": [
    "Claude asks us to use a tool. Claudette handles that automatically by just passing back the message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09196e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The email address for customer C1 is john@example.com.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(r)\n",
    "contents(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe5edb",
   "metadata": {},
   "source": [
    "Let's consider a more complex case than in the original example -- what happens if a customer wants to cancel all of their orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa531d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextBlock(text=\"Okay, let's cancel all orders for customer C1:\", type='text'),\n",
       " ToolUseBlock(id='toolu_014b5cwjteMFrfiipkfrnUqe', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(models[-1], tools=tools)\n",
    "r = chat('Please cancel all orders for customer C1 for me.')\n",
    "print(r.stop_reason)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2432a1",
   "metadata": {},
   "source": [
    "This is the start of a multi-stage tool use process. Doing it manually step by step is inconvenient, so let's write a function to handle this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def toolloop(self:Chat,\n",
    "             pr, # Prompt to pass to Claude\n",
    "             max_steps=10, # Maximum number of tool requests to loop through\n",
    "             temp=0, # Temperature\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             stop:Optional[list[str]]=None, # Stop sequences\n",
    "             trace_func:Optional[callable]=None, # Function to trace tool use steps (e.g `print`)\n",
    "             cont_func:Optional[callable]=noop, # Function that stops loop if returns False\n",
    "             **kw):\n",
    "    \"Add prompt `pr` to dialog and get a response from Claude, automatically following up with `tool_use` messages\"\n",
    "    r = self(pr, temp=temp, maxtok=maxtok, stop=stop, **kw)\n",
    "    for i in range(max_steps):\n",
    "        if r.stop_reason!='tool_use': break\n",
    "        if trace_func: trace_func(r)\n",
    "        r = self(r, temp=temp, maxtok=maxtok, stop=stop, **kw)\n",
    "        if not (cont_func or noop)(self.h[-2]['content']): break\n",
    "    if trace_func: trace_func(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a0859",
   "metadata": {},
   "source": [
    "We'll start by re-running our previous request - we shouldn't have to manually pass back the `tool_use` message any more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa6634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The email address for customer C1 is john@example.com.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: msg_01ERavPVumKbjcBwzV9A9KnP\n",
       "- content: [{'text': 'The email address for customer C1 is john@example.com.', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 732, 'output_tokens': 19}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01ERavPVumKbjcBwzV9A9KnP', content=[TextBlock(text='The email address for customer C1 is john@example.com.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 732; Out: 19; Total: 751)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(models[-1], tools=tools)\n",
    "r = chat.toolloop('Can you tell me the email address for customer C1?')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6131f0",
   "metadata": {},
   "source": [
    "Let's see if it can handle the multi-stage process now -- we'll add `show_trace=print` to see each stage of the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d3eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolsBetaMessage(id='msg_012Sbm2jveMi3ouecS6DMHRY', content=[TextBlock(text=\"Okay, let's cancel all orders for customer C1:\", type='text'), ToolUseBlock(id='toolu_01Arr363MLPLPHSx964NELuU', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 537; Out: 72; Total: 609)\n",
      "- Retrieving customer C1\n",
      "ToolsBetaMessage(id='msg_01NRhKJ7YoCfoFqAMbNj6dSN', content=[TextBlock(text=\"Based on the customer information, it looks like there are 2 orders for customer C1:\\n- Order O1 for Widget A (2 units)\\n- Order O2 for Gadget B (1 unit)\\n\\nLet's go ahead and cancel both of these orders:\", type='text'), ToolUseBlock(id='toolu_018L3295hgnuvbF5onrywX8F', input={'order_id': 'O1'}, name='cancel_order', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 746; Out: 120; Total: 866)\n",
      "- Cancelling order O1\n",
      "ToolsBetaMessage(id='msg_01YAtzCGQ5aSMpuRHmg4tvNh', content=[ToolUseBlock(id='toolu_01Ck2KaGj4JWeYR3cp3trTkj', input={'order_id': 'O2'}, name='cancel_order', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 878; Out: 57; Total: 935)\n",
      "- Cancelling order O2\n",
      "ToolsBetaMessage(id='msg_01XogPyPAm6V3y6he5xATR2M', content=[TextBlock(text='Both order cancellations were successful. All orders for customer C1 have now been cancelled.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 947; Out: 24; Total: 971)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Both order cancellations were successful. All orders for customer C1 have now been cancelled.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: msg_01XogPyPAm6V3y6he5xATR2M\n",
       "- content: [{'text': 'Both order cancellations were successful. All orders for customer C1 have now been cancelled.', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 947, 'output_tokens': 24}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01XogPyPAm6V3y6he5xATR2M', content=[TextBlock(text='Both order cancellations were successful. All orders for customer C1 have now been cancelled.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 947; Out: 24; Total: 971)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(models[-1], tools=tools)\n",
    "r = chat.toolloop('Please cancel all orders for customer C1 for me.', trace_func=print)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8c9fc",
   "metadata": {},
   "source": [
    "OK Claude thinks the orders were cancelled -- let's check one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving order O2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The status of order O2 is 'Cancelled'. This matches the information we had earlier when retrieving the customer's order details.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: msg_01UATtkDp2nagKAaXvd93zSZ\n",
       "- content: [{'text': \"The status of order O2 is 'Cancelled'. This matches the information we had earlier when retrieving the customer's order details.\", 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 1107, 'output_tokens': 33}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01UATtkDp2nagKAaXvd93zSZ', content=[TextBlock(text=\"The status of order O2 is 'Cancelled'. This matches the information we had earlier when retrieving the customer's order details.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1107; Out: 33; Total: 1140)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop('What is the status of order O2?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a93494",
   "metadata": {},
   "source": [
    "## Code interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aeee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmtools import python\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a170c9",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- pass code directly to run in shell\n",
    "- use shell\n",
    "- download notebook when done, or open in colab\n",
    "- image outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = 'os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(\n",
    "): # Username of current user\n",
    "    \"Get the username of the user running this session\"\n",
    "    return 'Jeremy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_python(code:str,   # Code to execute in persistent IPython session\n",
    "               ): # Result of last expression (if exists), or '#DECLINED#' if users declines request to exectute code\n",
    "    \"Executes python `code` with `timeout` using a persistent IPython session and returns expression on the last line.\"\n",
    "    confirm = f'Press Enter to execute, or enter \"n\" to skip?\\n```\\n{code}\\n```\\n'\n",
    "    if input(confirm): return '#DECLINED#'\n",
    "    try:\n",
    "        res = python('import '+imps+code)\n",
    "        print('--', res)\n",
    "        return res\n",
    "    except Exception as e: return traceback.format_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [call_python,get_user]\n",
    "sp = f'''Don't do complex calculations yourself -- use code for them.\n",
    "The following modules are pre-imported for `call_python` automatically:\n",
    "\n",
    "{imps}\n",
    "\n",
    "Never mention what tools you are using.'''\n",
    "chat = Chat(models[-1], tools=tools)#, sp=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.h = ['Can you multiply numbers together yourself?',\n",
    "         'No, but I can use code to do so.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_cts(r): print(contents(r))\n",
    "def _cont_decline(c): return c[0]['content']!='#DECLINED#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = '''Create a function `checksum` for a string `s`,\n",
    "# that multiplies together the ascii values of each character in `s`.'''\n",
    "# chat.toolloop(pr, trace_func=_show_cts, temp=0, cont_func=_stop_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d44120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's calculate the \"checksum\" by multiplying the ASCII values of the characters in the username.\n",
      "-- [{'type': 'tool_result', 'tool_use_id': 'toolu_01Ekbyk52YMBy5Luj83AggV7', 'content': 'Jeremy'}]\n",
      "ToolUseBlock(id='toolu_01V3uNiY3o6xTMBXN1fKfT5w', input={'code': 'import functools\\n\\nusername = \"Jeremy\"\\nchecksum = functools.reduce(lambda x, y: x * y, [ord(c) for c in username])\\n\\nprint(int(checksum))'}, name='call_python', type='tool_use')\n",
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "import functools\n",
      "\n",
      "username = \"Jeremy\"\n",
      "checksum = functools.reduce(lambda x, y: x * y, [ord(c) for c in username])\n",
      "\n",
      "print(int(checksum))\n",
      "```\n",
      "\n",
      "-- 1134987783204\n",
      "-- [{'type': 'tool_result', 'tool_use_id': 'toolu_01V3uNiY3o6xTMBXN1fKfT5w', 'content': '1134987783204'}]\n",
      "The checksum, calculated by multiplying the ASCII values of the characters in the username \"Jeremy\", is 1134987783204.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The checksum, calculated by multiplying the ASCII values of the characters in the username \"Jeremy\", is 1134987783204.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: msg_01No3VLqgdKZM4Z3QTdbk2nc\n",
       "- content: [{'text': 'The checksum, calculated by multiplying the ASCII values of the characters in the username \"Jeremy\", is 1134987783204.', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 646, 'output_tokens': 32}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01No3VLqgdKZM4Z3QTdbk2nc', content=[TextBlock(text='The checksum, calculated by multiplying the ASCII values of the characters in the username \"Jeremy\", is 1134987783204.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 646; Out: 32; Total: 678)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = '''Please tell me the simple \"checksum\" of the user name running this session, by\n",
    "multiplying together the ascii values of each character of the name.'''\n",
    "chat.toolloop(pr, trace_func=_show_cts, temp=0, cont_func=_stop_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627b799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
