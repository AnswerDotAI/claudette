# Tool loop


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
import os
# os.environ['ANTHROPIC_LOG'] = 'debug'
```

``` python
from IPython.display import display, Markdown, clear_output
from pprint import pprint
```

``` python
model = models[1]
model
```

    'claude-sonnet-4-20250514'

## Problem setup

Anthropic provides an [interesting
example](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/customer_service_agent.ipynb)
of using tools to mock up a hypothetical ordering system. We’re going to
take it a step further, and show how we can dramatically simplify the
process, whilst completing more complex tasks.

We’ll start by defining the same mock customer/order data as in
Anthropic’s example, plus create a entity relationship between customers
and orders:

``` python
def _get_orders_customers():
    orders = {
        "O1": dict(id="O1", product="Widget A", quantity=2, price=19.99, status="Shipped"),
        "O2": dict(id="O2", product="Gadget B", quantity=1, price=49.99, status="Processing"),
        "O3": dict(id="O3", product="Gadget B", quantity=2, price=49.99, status="Shipped")}

    customers = {
        "C1": dict(name="John Doe", email="john@example.com", phone="123-456-7890",
                   orders=[orders['O1'], orders['O2']]),
        "C2": dict(name="Jane Smith", email="jane@example.com", phone="987-654-3210",
                   orders=[orders['O3']])
    }
    return orders, customers
```

``` python
orders, customers = _get_orders_customers()
```

We can now define the same functions from the original example – but
note that we don’t need to manually create the large JSON schema, since
Claudette handles all that for us automatically from the functions
directly. We’ll add some extra functionality to update order details
when cancelling too.

``` python
def get_customer_info(
    customer_id:str # ID of the customer
): # Customer's name, email, phone number, and list of orders
    "Retrieves a customer's information and their orders based on the customer ID"
    print(f'- Retrieving customer {customer_id}')
    return customers.get(customer_id, "Customer not found")

def get_order_details(
    order_id:str # ID of the order
): # Order's ID, product name, quantity, price, and order status
    "Retrieves the details of a specific order based on the order ID"
    print(f'- Retrieving order {order_id}')
    return orders.get(order_id, "Order not found")

def cancel_order(
    order_id:str # ID of the order to cancel
)->bool: # True if the cancellation is successful
    "Cancels an order based on the provided order ID"
    print(f'- Cancelling order {order_id}')
    if order_id not in orders: return False
    orders[order_id]['status'] = 'Cancelled'
    return True
```

We’re now ready to start our chat.

## Manual tool use

``` python
tools = [get_customer_info, get_order_details, cancel_order]
```

``` python
chat = Chat(model, tools=tools)
```

We’ll start with the same request as Anthropic showed:

``` python
r = chat('Can you tell me the email address for customer C1?')
print(r.stop_reason)
r.content
```

    - Retrieving customer C1
    tool_use

    [TextBlock(citations=None, text="I'll retrieve the customer information for customer C1 to find their email address.", type='text'),
     ToolUseBlock(id='toolu_01DssUaVrzak7NdUGPj6NDew', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]

Claude asks us to use a tool. Claudette handles that automatically by
just calling it again:

``` python
r = chat()
contents(r)
```

    'The email address for customer C1 (John Doe) is john@example.com.'

Let’s consider a more complex case than in the original example – what
happens if a customer wants to cancel all of their orders?

``` python
chat = Chat(model, tools=tools)
r = chat('Please cancel all orders for customer C1 for me.')
print(r.stop_reason)
r.content
```

    - Retrieving customer C1
    tool_use

    [TextBlock(citations=None, text="I'll help you cancel all orders for customer C1. First, let me retrieve the customer's information to see what orders they have.", type='text'),
     ToolUseBlock(id='toolu_01KmVciyCHYUuc8fvta1Kodw', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')]

## Tool loop

This is the start of a multi-stage tool use process. Doing it manually
step by step is inconvenient, so let’s write a function to handle this
for us:

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/toolloop.py#L21"
target="_blank" style="float:right; font-size:smaller">source</a>

### Chat.toolloop

>  Chat.toolloop (pr, max_steps=10, cont_func:<built-
>                     infunctioncallable>=<function noop>, final_prompt='You
>                     have no more tool uses. Please summarize your findings. If
>                     you did not complete your goal please tell the user what
>                     further work needs to be done so they can choose how best
>                     to proceed.', temp=None, maxtok=4096, maxthinktok=0,
>                     stream=False, prefill='', tool_choice:Optional[dict]=None)

*Add prompt `pr` to dialog and get a response from Claude, automatically
following up with `tool_use` messages*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>pr</td>
<td></td>
<td></td>
<td>Prompt to pass to Claude</td>
</tr>
<tr>
<td>max_steps</td>
<td>int</td>
<td>10</td>
<td>Maximum number of tool requests to loop through</td>
</tr>
<tr>
<td>cont_func</td>
<td>callable</td>
<td>noop</td>
<td>Function that stops loop if returns False</td>
</tr>
<tr>
<td>final_prompt</td>
<td>str</td>
<td>You have no more tool uses. Please summarize your findings. If you
did not complete your goal please tell the user what further work needs
to be done so they can choose how best to proceed.</td>
<td>Prompt to add if last message is a tool call</td>
</tr>
<tr>
<td>temp</td>
<td>NoneType</td>
<td>None</td>
<td>Temperature</td>
</tr>
<tr>
<td>maxtok</td>
<td>int</td>
<td>4096</td>
<td>Maximum tokens</td>
</tr>
<tr>
<td>maxthinktok</td>
<td>int</td>
<td>0</td>
<td>Maximum thinking tokens</td>
</tr>
<tr>
<td>stream</td>
<td>bool</td>
<td>False</td>
<td>Stream response?</td>
</tr>
<tr>
<td>prefill</td>
<td>str</td>
<td></td>
<td>Optional prefill to pass to Claude as start of its response</td>
</tr>
<tr>
<td>tool_choice</td>
<td>Optional</td>
<td>None</td>
<td>Optionally force use of some tool</td>
</tr>
</tbody>
</table>

<details open class="code-fold">
<summary>Exported source</summary>

``` python
_final_prompt = "You have no more tool uses. Please summarize your findings. If you did not complete your goal please tell the user what further work needs to be done so they can choose how best to proceed."
```

</details>

<details open class="code-fold">
<summary>Exported source</summary>

``` python
@patch
@delegates(Chat.__call__)
def toolloop(self:Chat,
             pr, # Prompt to pass to Claude
             max_steps=10, # Maximum number of tool requests to loop through
             cont_func:callable=noop, # Function that stops loop if returns False
             final_prompt=_final_prompt, # Prompt to add if last message is a tool call
             **kwargs):
    "Add prompt `pr` to dialog and get a response from Claude, automatically following up with `tool_use` messages"
    @save_iter
    def _f(o):
        init_n = len(self.h)
        r = self(pr, **kwargs)
        yield r
        if len(self.last)>1: yield self.last[1]
        for i in range(max_steps-1):
            if self.c.stop_reason!='tool_use': break
            r = self(final_prompt if i==max_steps-2 else None, **kwargs)
            yield r
            if len(self.last)>1: yield self.last[1]
            if not cont_func(*self.h[-3:]): break
        o.value = self.h[init_n+1:]
    return _f()
```

</details>

`toolloop` returns an iterable of assistant messages:

``` python
chat = Chat(model, tools=tools)
pr = 'Can you tell me the email address for customer C1?'
r = chat.toolloop(pr)
for o in r: display(o)
```

    - Retrieving customer C1

I’ll retrieve the customer information for customer C1 to find their
email address.

<details>

- id: `msg_01FceFbpqXnDqVz52Fhe8q7V`
- content:
  `[{'citations': None, 'text': "I'll retrieve the customer information for customer C1 to find their email address.", 'type': 'text'}, {'id': 'toolu_01LgZAchaBD41S5cMtfyCcCK', 'input': {'customer_id': 'C1'}, 'name': 'get_customer_info', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 574, 'output_tokens': 76, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': "{'name': 'John Doe', 'email': 'john@example.com', "
                            "'phone': '123-456-7890', 'orders': [{'id': 'O1', "
                            "'product': 'Widget A', 'quantity': 2, 'price': "
                            "19.99, 'status': 'Shipped'}, {'id': 'O2', "
                            "'product': 'Gadget B', 'quantity': 1, 'price': "
                            "49.99, 'status': 'Processing'}]}",
                 'tool_use_id': 'toolu_01LgZAchaBD41S5cMtfyCcCK',
                 'type': 'tool_result'}],
  'role': 'user'}
```

The email address for customer C1 (John Doe) is john@example.com.

<details>

- id: `msg_01GUwa8tSfNXyArxyp3J1WE7`
- content:
  `[{'citations': None, 'text': 'The email address for customer C1 (John Doe) is john@example.com.', 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 787, 'output_tokens': 23, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

The full set of tool loop messages is stored in the `value` attr:

``` python
pprint(r.value, width=120)
```

    [{'content': [{'citations': None,
                   'text': "I'll retrieve the customer information for customer C1 to find their email address.",
                   'type': 'text'},
                  {'id': 'toolu_01LgZAchaBD41S5cMtfyCcCK',
                   'input': {'customer_id': 'C1'},
                   'name': 'get_customer_info',
                   'type': 'tool_use'}],
      'role': 'assistant'},
     {'content': [{'content': "{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': "
                              "[{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Shipped'}, "
                              "{'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': "
                              "'Processing'}]}",
                   'tool_use_id': 'toolu_01LgZAchaBD41S5cMtfyCcCK',
                   'type': 'tool_result'}],
      'role': 'user'},
     {'content': [{'citations': None,
                   'text': 'The email address for customer C1 (John Doe) is john@example.com.',
                   'type': 'text'}],
      'role': 'assistant'}]

Let’s see if it can handle the multi-stage process now:

``` python
orders, customers = _get_orders_customers()
```

``` python
chat = Chat(model, tools=tools)
r = chat.toolloop('Please cancel all orders for customer C1 for me.')
for o in r: display(o)
```

    - Retrieving customer C1

I’ll help you cancel all orders for customer C1. First, let me retrieve
the customer’s information to see what orders they have.

<details>

- id: `msg_01BB74fAtb9WwLaugJz8vxkR`
- content:
  `[{'citations': None, 'text': "I'll help you cancel all orders for customer C1. First, let me retrieve the customer's information to see what orders they have.", 'type': 'text'}, {'id': 'toolu_01LVxXgG6L5dMagAmqaRS7Tp', 'input': {'customer_id': 'C1'}, 'name': 'get_customer_info', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 574, 'output_tokens': 87, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': "{'name': 'John Doe', 'email': 'john@example.com', "
                            "'phone': '123-456-7890', 'orders': [{'id': 'O1', "
                            "'product': 'Widget A', 'quantity': 2, 'price': "
                            "19.99, 'status': 'Shipped'}, {'id': 'O2', "
                            "'product': 'Gadget B', 'quantity': 1, 'price': "
                            "49.99, 'status': 'Processing'}]}",
                 'tool_use_id': 'toolu_01LVxXgG6L5dMagAmqaRS7Tp',
                 'type': 'tool_result'}],
  'role': 'user'}
```

    - Cancelling order O1
    - Cancelling order O2

I can see that customer C1 (John Doe) has 2 orders: - Order O1: Widget A
(Status: Shipped) - Order O2: Gadget B (Status: Processing)

Now I’ll cancel both orders for you:

<details>

- id: `msg_01LPjUKheGbdjZkDHZFdt6r9`
- content:
  `[{'citations': None, 'text': "I can see that customer C1 (John Doe) has 2 orders:\n- Order O1: Widget A (Status: Shipped)\n- Order O2: Gadget B (Status: Processing)\n\nNow I'll cancel both orders for you:", 'type': 'text'}, {'id': 'toolu_013AgYM2wjo5pYEBwGhFtF2M', 'input': {'order_id': 'O1'}, 'name': 'cancel_order', 'type': 'tool_use'}, {'id': 'toolu_01DXHrux8YresN2xGENV22jg', 'input': {'order_id': 'O2'}, 'name': 'cancel_order', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 798, 'output_tokens': 154, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': 'True',
                 'tool_use_id': 'toolu_013AgYM2wjo5pYEBwGhFtF2M',
                 'type': 'tool_result'},
               { 'content': 'True',
                 'tool_use_id': 'toolu_01DXHrux8YresN2xGENV22jg',
                 'type': 'tool_result'}],
  'role': 'user'}
```

Perfect! I’ve successfully canceled all orders for customer C1 (John
Doe):

✅ **Order O1** (Widget A) - Canceled ✅ **Order O2** (Gadget B) -
Canceled

Both orders have been canceled successfully. The customer will likely
receive confirmation of these cancellations via email at
john@example.com.

<details>

- id: `msg_01KJtjuMJtnPkfMmotZm3iSX`
- content:
  `[{'citations': None, 'text': "Perfect! I've successfully canceled all orders for customer C1 (John Doe):\n\n✅ **Order O1** (Widget A) - Canceled\n✅ **Order O2** (Gadget B) - Canceled\n\nBoth orders have been canceled successfully. The customer will likely receive confirmation of these cancellations via email at john@example.com.", 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1017, 'output_tokens': 83, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

OK Claude thinks the orders were cancelled – let’s check one:

``` python
for o in chat.toolloop('What is the status of order O2?'): display(o)
```

    - Retrieving order O2

Let me check the current status of order O2 for you.

<details>

- id: `msg_01Viv8k9VnJmQKPef8hzfrqv`
- content:
  `[{'citations': None, 'text': 'Let me check the current status of order O2 for you.', 'type': 'text'}, {'id': 'toolu_016fGa56xvcA9tmVZ8a9gAZP', 'input': {'order_id': 'O2'}, 'name': 'get_order_details', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1112, 'output_tokens': 73, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': "{'id': 'O2', 'product': 'Gadget B', 'quantity': "
                            "1, 'price': 49.99, 'status': 'Cancelled'}",
                 'tool_use_id': 'toolu_016fGa56xvcA9tmVZ8a9gAZP',
                 'type': 'tool_result'}],
  'role': 'user'}
```

The status of order O2 is **Cancelled**.

This confirms that the cancellation we performed earlier was successful.
The order for 1 Gadget B (priced at $49.99) has been officially
cancelled in the system.

<details>

- id: `msg_01EJyBiVtGjTbxyNVP7SF2Bq`
- content:
  `[{'citations': None, 'text': 'The status of order O2 is **Cancelled**. \n\nThis confirms that the cancellation we performed earlier was successful. The order for 1 Gadget B (priced at $49.99) has been officially cancelled in the system.', 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1241, 'output_tokens': 57, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

If we run out of tool loops lets see what happens:

``` python
def mydiv(a:float, b:float):
    "Divide two numbers"
    return a / b
```

``` python
chat = Chat(model, tools=[mydiv])
r = chat.toolloop('Please calculate this sequence using your tools: 43/23454; 652/previous result; 6843/previous result; 321/previous result', max_steps=2)
for o in r: display(o)
```

I’ll calculate this sequence step by step using the division tool.

<details>

- id: `msg_01KoEBvzjwwhdoViUXq3C6h3`
- content:
  `[{'citations': None, 'text': "I'll calculate this sequence step by step using the division tool.", 'type': 'text'}, {'id': 'toolu_01LwB9cpaVED1e8JLVzt55yh', 'input': {'a': 43, 'b': 23454}, 'name': 'mydiv', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 424, 'output_tokens': 84, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': '0.001833375969983798',
                 'tool_use_id': 'toolu_01LwB9cpaVED1e8JLVzt55yh',
                 'type': 'tool_result'}],
  'role': 'user'}
```

I was able to complete the first two steps of your sequence:

**Completed calculations:** 1. 43 ÷ 23454 = 0.001833375969983798 2. 652
÷ 0.001833375969983798 = 355628.0930232558

**Remaining work needed:** I was unable to complete the full sequence
due to tool usage limits. To finish the calculation, you would need:

3.  6843 ÷ 355628.0930232558 (divide 6843 by the result from step 2)
4.  321 ÷ \[result from step 3\] (divide 321 by the result from step 3)

You can either ask me to continue with these remaining calculations in a
new conversation, or perform these final two divisions using a
calculator with the intermediate result I provided: 355628.0930232558.

<details>

- id: `msg_01N6GJ4SZdCXcgG5fA1mb8Pf`
- content:
  `[{'citations': None, 'text': 'I was able to complete the first two steps of your sequence:\n\n**Completed calculations:**\n1. 43 ÷ 23454 = 0.001833375969983798\n2. 652 ÷ 0.001833375969983798 = 355628.0930232558\n\n**Remaining work needed:**\nI was unable to complete the full sequence due to tool usage limits. To finish the calculation, you would need:\n\n3. 6843 ÷ 355628.0930232558 (divide 6843 by the result from step 2)\n4. 321 ÷ [result from step 3] (divide 321 by the result from step 3)\n\nYou can either ask me to continue with these remaining calculations in a new conversation, or perform these final two divisions using a calculator with the intermediate result I provided: 355628.0930232558.', 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 681, 'output_tokens': 212, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` python
chat = Chat(model, tools=mydiv)
r = chat.toolloop('Try dividing 1 by 0 and see what the error result is')
for o in r: display(o)
```

I’ll try dividing 1 by 0 to see what error occurs:

<details>

- id: `msg_011h7rWf61BEm5rgE9cUkc5P`
- content:
  `[{'citations': None, 'text': "I'll try dividing 1 by 0 to see what error occurs:", 'type': 'text'}, {'id': 'toolu_01TRpZtRfRopM86K97WdyL33', 'input': {'a': 1, 'b': 0}, 'name': 'mydiv', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 409, 'output_tokens': 88, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': 'Traceback (most recent call last):\n'
                            '  File '
                            '"/Users/jhoward/aai-ws/toolslm/toolslm/funccall.py", '
                            'line 203, in call_func\n'
                            '    try: return func(**fc_inputs)\n'
                            '                ^^^^^^^^^^^^^^^^^\n'
                            '  File '
                            '"/Users/jhoward/aai-ws/claudette/claudette/core.py", '
                            'line 403, in wrapper\n'
                            '    return func(*new_args, **new_kwargs)\n'
                            '           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n'
                            '  File '
                            '"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_50014/246724137.py", '
                            'line 3, in mydiv\n'
                            '    return a / b\n'
                            '           ~~^~~\n'
                            'ZeroDivisionError: division by zero\n',
                 'tool_use_id': 'toolu_01TRpZtRfRopM86K97WdyL33',
                 'type': 'tool_result'}],
  'role': 'user'}
```

As expected, dividing 1 by 0 resulted in a
`ZeroDivisionError: division by zero` error. This is the standard Python
error that occurs when attempting to divide any number by zero, since
division by zero is mathematically undefined.

The error traceback shows that the error occurred in the `mydiv`
function at the line `return a / b` when `a=1` and `b=0`.

<details>

- id: `msg_013MaeWRfrzKFmBktVk4Tf1Q`
- content:
  `[{'citations': None, 'text': 'As expected, dividing 1 by 0 resulted in a`ZeroDivisionError:
  division by
  zero`error. This is the standard Python error that occurs when attempting to divide any number by zero, since division by zero is mathematically undefined.\n\nThe error traceback shows that the error occurred in the`mydiv`function at the line`return
  a / b`when`a=1`and`b=0`.', 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 701, 'output_tokens': 96, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

## Streaming

``` python
orders, customers = _get_orders_customers()
```

``` python
chat = Chat(model, tools=tools)
r = chat.toolloop('Please cancel all orders for customer C1 for me.', stream=True)
for o in r:
    if isinstance(o, (dict,Message,list)): print(o)
    else: 
        for x in o: print(x, end='')
        display(o.value)
```

    I'll help you cancel all orders for customer C1. First, let me retrieve the customer's information to see what orders they have.- Retrieving customer C1

I’ll help you cancel all orders for customer C1. First, let me retrieve
the customer’s information to see what orders they have.

<details>

- id: `msg_01Jyn1EKFLTxMDa4rCF8bu5J`
- content:
  `[{'citations': None, 'text': "I'll help you cancel all orders for customer C1. First, let me retrieve the customer's information to see what orders they have.", 'type': 'text'}, {'id': 'toolu_01E5czFAs5ZUQS3mmrfdr4rd', 'input': {'customer_id': 'C1'}, 'name': 'get_customer_info', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 574, 'output_tokens': 87, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

    {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01E5czFAs5ZUQS3mmrfdr4rd', 'content': "{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Shipped'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}]}"}]}
    I can see that customer C1 (John Doe) has 2 orders:
    - Order O1: Widget A (Status: Shipped)
    - Order O2: Gadget B (Status: Processing)

    Now I'll cancel both orders for you:- Cancelling order O1
    - Cancelling order O2

I can see that customer C1 (John Doe) has 2 orders: - Order O1: Widget A
(Status: Shipped) - Order O2: Gadget B (Status: Processing)

Now I’ll cancel both orders for you:

<details>

- id: `msg_01XYHjJAXTyHGF4zvzcZqHqp`
- content:
  `[{'citations': None, 'text': "I can see that customer C1 (John Doe) has 2 orders:\n- Order O1: Widget A (Status: Shipped)\n- Order O2: Gadget B (Status: Processing)\n\nNow I'll cancel both orders for you:", 'type': 'text'}, {'id': 'toolu_01BesZhbP28GK2iQZp5fLNjj', 'input': {'order_id': 'O1'}, 'name': 'cancel_order', 'type': 'tool_use'}, {'id': 'toolu_01SLArB7rm7MLzNvrp3iDDxd', 'input': {'order_id': 'O2'}, 'name': 'cancel_order', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 798, 'output_tokens': 154, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

    {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01BesZhbP28GK2iQZp5fLNjj', 'content': 'True'}, {'type': 'tool_result', 'tool_use_id': 'toolu_01SLArB7rm7MLzNvrp3iDDxd', 'content': 'True'}]}
    Perfect! I've successfully canceled all orders for customer C1 (John Doe):

    ✅ **Order O1** (Widget A) - Canceled
    ✅ **Order O2** (Gadget B) - Canceled

    Both orders have been canceled successfully. The customer will likely receive confirmation of these cancellations via email at john@example.com.

Perfect! I’ve successfully canceled all orders for customer C1 (John
Doe):

✅ **Order O1** (Widget A) - Canceled ✅ **Order O2** (Gadget B) -
Canceled

Both orders have been canceled successfully. The customer will likely
receive confirmation of these cancellations via email at
john@example.com.

<details>

- id: `msg_012Fh7FuLy1aQ7Aw2NZoFeh8`
- content:
  `[{'citations': None, 'text': "Perfect! I've successfully canceled all orders for customer C1 (John Doe):\n\n✅ **Order O1** (Widget A) - Canceled\n✅ **Order O2** (Gadget B) - Canceled\n\nBoth orders have been canceled successfully. The customer will likely receive confirmation of these cancellations via email at john@example.com.", 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1017, 'output_tokens': 83, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

## Async tool loop

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/toolloop.py#L49"
target="_blank" style="float:right; font-size:smaller">source</a>

### AsyncChat.toolloop

>  AsyncChat.toolloop (pr, max_steps=10, cont_func:<built-
>                          infunctioncallable>=<function noop>,
>                          final_prompt='You have no more tool uses. Please
>                          summarize your findings. If you did not complete your
>                          goal please tell the user what further work needs to
>                          be done so they can choose how best to proceed.',
>                          temp=None, maxtok=4096, maxthinktok=0, stream=False,
>                          prefill='',
>                          tool_choice:Union[str,bool,dict,NoneType]=None)

*Add prompt `pr` to dialog and get a response from Claude, automatically
following up with `tool_use` messages*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>pr</td>
<td></td>
<td></td>
<td>Prompt to pass to Claude</td>
</tr>
<tr>
<td>max_steps</td>
<td>int</td>
<td>10</td>
<td>Maximum number of tool requests to loop through</td>
</tr>
<tr>
<td>cont_func</td>
<td>callable</td>
<td>noop</td>
<td>Function that stops loop if returns False</td>
</tr>
<tr>
<td>final_prompt</td>
<td>str</td>
<td>You have no more tool uses. Please summarize your findings. If you
did not complete your goal please tell the user what further work needs
to be done so they can choose how best to proceed.</td>
<td>Prompt to add if last message is a tool call</td>
</tr>
<tr>
<td>temp</td>
<td>NoneType</td>
<td>None</td>
<td>Temperature</td>
</tr>
<tr>
<td>maxtok</td>
<td>int</td>
<td>4096</td>
<td>Maximum tokens</td>
</tr>
<tr>
<td>maxthinktok</td>
<td>int</td>
<td>0</td>
<td>Maximum thinking tokens</td>
</tr>
<tr>
<td>stream</td>
<td>bool</td>
<td>False</td>
<td>Stream response?</td>
</tr>
<tr>
<td>prefill</td>
<td>str</td>
<td></td>
<td>Optional prefill to pass to Claude as start of its response</td>
</tr>
<tr>
<td>tool_choice</td>
<td>Union</td>
<td>None</td>
<td>Optionally force use of some tool</td>
</tr>
</tbody>
</table>

<details open class="code-fold">
<summary>Exported source</summary>

``` python
@patch
@delegates(AsyncChat.__call__)
def toolloop(
    self: AsyncChat,
    pr, # Prompt to pass to Claude
    max_steps=10, # Maximum number of tool requests to loop through
    cont_func: callable = noop, # Function that stops loop if returns False
    final_prompt = _final_prompt, # Prompt to add if last message is a tool call
    **kwargs
):
    "Add prompt `pr` to dialog and get a response from Claude, automatically following up with `tool_use` messages"
    @save_iter
    async def _f(o):
        init_n = len(self.h)
        r = await self(pr, **kwargs)
        yield r
        if len(self.last)>1: yield self.last[1]
        for i in range(max_steps-1):
            if self.c.stop_reason != 'tool_use': break
            r = await self(final_prompt if i==max_steps-2 else None, **kwargs)
            yield r
            if len(self.last)>1: yield self.last[1]
            if not cont_func(*self.h[-3:]): break
        o.value = self.h[init_n+1:]
    return _f()
```

</details>

``` python
orders, customers = _get_orders_customers()
```

``` python
tools = [get_customer_info, get_order_details, cancel_order]
chat = AsyncChat(model, tools=tools)
r = chat.toolloop('Can you tell me the email address for customer C1?')
async for o in r: print(o)
```

    - Retrieving customer C1
    Message(id='msg_011k575B2yD12nYXtkwQ6gTg', content=[TextBlock(citations=None, text="I'll retrieve the customer information for customer C1 to find their email address.", type='text'), ToolUseBlock(id='toolu_01Qh5FvPYBR2L2oQMebNH1Ey', input={'customer_id': 'C1'}, name='get_customer_info', type='tool_use')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 574; Out: 76; Cache create: 0; Cache read: 0; Total Tokens: 650; Search: 0)
    {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_01Qh5FvPYBR2L2oQMebNH1Ey', 'content': "{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Shipped'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}]}"}]}
    Message(id='msg_011MhL2oQ1L3nWzXDxFDJYuA', content=[TextBlock(citations=None, text='The email address for customer C1 (John Doe) is john@example.com.', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 787; Out: 23; Cache create: 0; Cache read: 0; Total Tokens: 810; Search: 0)

``` python
pprint(r.value)
```

    [{'content': [{'citations': None,
                   'text': "I'll retrieve the customer information for customer C1 "
                           'to find their email address.',
                   'type': 'text'},
                  {'id': 'toolu_01EKTxYukVVQtAExBzenW3d7',
                   'input': {'customer_id': 'C1'},
                   'name': 'get_customer_info',
                   'type': 'tool_use'}],
      'role': 'assistant'},
     {'content': [{'content': "{'name': 'John Doe', 'email': 'john@example.com', "
                              "'phone': '123-456-7890', 'orders': [{'id': 'O1', "
                              "'product': 'Widget A', 'quantity': 2, 'price': "
                              "19.99, 'status': 'Shipped'}, {'id': 'O2', "
                              "'product': 'Gadget B', 'quantity': 1, 'price': "
                              "49.99, 'status': 'Processing'}]}",
                   'tool_use_id': 'toolu_01EKTxYukVVQtAExBzenW3d7',
                   'type': 'tool_result'}],
      'role': 'user'},
     {'content': [{'citations': None,
                   'text': 'The email address for customer C1 (John Doe) is '
                           'john@example.com.',
                   'type': 'text'}],
      'role': 'assistant'}]

## Code interpreter

Here is an example of using `toolloop` to implement a simple code
interpreter with additional tools.

``` python
from toolslm.shell import get_shell
from fastcore.meta import delegates
import traceback
```

``` python
@delegates()
class CodeChat(Chat):
    imps = 'os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses'
    def __init__(self, model: Optional[str] = None, ask:bool=True, **kwargs):
        super().__init__(model=model, **kwargs)
        self.ask = ask
        self.tools.append(self.run_cell)
        self.shell = get_shell()
        self.shell.run_cell('import '+self.imps)
```

We have one additional parameter to creating a `CodeChat` beyond what we
pass to [`Chat`](https://claudette.answer.ai/core.html#chat), which is
`ask` – if that’s `True`, we’ll prompt the user before running code.

``` python
@patch
def run_cell(
    self:CodeChat,
    code:str,   # Code to execute in persistent IPython session
)->str:
    """Asks user for permission, and if provided, executes python `code` using persistent IPython session.
    Returns: Result of expression on last line (if exists); '#DECLINED#' if user declines request to execute"""
    confirm = f'Press Enter to execute, or enter "n" to skip?\n```\n{code}\n```\n'
    if self.ask and input(confirm): return '#DECLINED#'
    try: res = self.shell.run_cell(code)
    except Exception as e: return traceback.format_exc()
    return res.stdout if res.result is None else res.result
```

We just pass along requests to run code to the shell’s implementation.
Claude often prints results instead of just using the last expression,
so we capture stdout in those cases.

``` python
sp = f'''You are a knowledgable assistant. Do not use tools unless needed.
Don't do complex calculations yourself -- use code for them.
The following modules are pre-imported for `run_cell` automatically:

{CodeChat.imps}

Never mention what tools you are using. Note that `run_cell` interpreter state is *persistent* across calls.

If a tool returns `#DECLINED#` report to the user that the attempt was declined and no further progress can be made.
In that case, do *not* attempt to run any further code -- stop execution *IMMEDIATELY* and tell the user it was declined.

When using a tool, *ALWAYS* before every use of every tool, tell the user what you will be doing and why.'''
```

``` python
def get_user()->str:
    "Get the username of the user running this session"
    print("Looking up username")
    return 'Jeremy'
```

In order to test out multi-stage tool use, we create a mock function
that Claude can call to get the current username.

``` python
model = models[1]
chat = CodeChat(model, tools=[get_user], sp=sp, ask=True, temp=0.3)
```

Providing a callable to toolloop’s `trace_func` lets us print out
information during the loop:

`toolloop`’s `cont_func` callable let’s us provide a function which, if
it returns `False`, stops the loop:

``` python
def _cont_decline(call, resp, asst): return resp['content'][0]['content'] != '#DECLINED#'
```

Now we can try our code interpreter. We start by asking for a function
to be created, which we’ll use in the next prompt to test that the
interpreter is persistent.

``` python
pr = '''Create a 1-line function `checksum` for a string `s`,
that multiplies together the ascii values of each character in `s` using `reduce`.'''
for o in chat.toolloop(pr, cont_func=_cont_decline): display(o)
```

    Press Enter to execute, or enter "n" to skip?
    ```
    # Create the 1-line checksum function using reduce
    checksum = lambda s: functools.reduce(operator.mul, (ord(c) for c in s), 1)

    # Test it with a few examples
    print("checksum('abc'):", checksum('abc'))
    print("checksum('hello'):", checksum('hello'))
    print("checksum('A'):", checksum('A'))
    print("checksum(''):", checksum(''))  # Empty string test
    ```

I’ll create a 1-line checksum function that multiplies the ASCII values
of characters in a string using `reduce`.

<details>

- id: `msg_01PWJZzxGGJJg1Ywu5jXxZXC`
- content:
  `[{'citations': None, 'text': "I'll create a 1-line checksum function that multiplies the ASCII values of characters in a string using`reduce`.", 'type': 'text'}, {'id': 'toolu_01PnYwW6vG44rqUvzUU2FsQm', 'input': {'code': '# Create the 1-line checksum function using reduce\nchecksum = lambda s: functools.reduce(operator.mul, (ord(c) for c in s), 1)\n\n# Test it with a few examples\nprint("checksum(\'abc\'):", checksum(\'abc\'))\nprint("checksum(\'hello\'):", checksum(\'hello\'))\nprint("checksum(\'A\'):", checksum(\'A\'))\nprint("checksum(\'\'):", checksum(\'\'))  # Empty string test'}, 'name': 'run_cell', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 744, 'output_tokens': 188, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': "checksum('abc'): 941094\n"
                            "checksum('hello'): 13599570816\n"
                            "checksum('A'): 65\n"
                            "checksum(''): 1\n",
                 'tool_use_id': 'toolu_01PnYwW6vG44rqUvzUU2FsQm',
                 'type': 'tool_result'}],
  'role': 'user'}
```

Perfect! Here’s the 1-line checksum function:

``` python
checksum = lambda s: functools.reduce(operator.mul, (ord(c) for c in s), 1)
```

This function: - Uses `functools.reduce` with `operator.mul` to multiply
values together - Converts each character to its ASCII value using
`ord(c)` - Uses a generator expression `(ord(c) for c in s)` to get
ASCII values - Starts with an initial value of `1` (the identity for
multiplication) - Returns `1` for empty strings (since there are no
characters to multiply)

The function works by multiplying together all the ASCII values of the
characters in the input string `s`.

<details>

- id: `msg_013yM4PQWnPxso5Rt38juKXz`
- content:
  ```` [{'citations': None, 'text': "Perfect! Here's the 1-line checksum function:\n\n```python\nchecksum = lambda s: functools.reduce(operator.mul, (ord(c) for c in s), 1)\n```\n\nThis function:\n- Uses ````functools.reduce`with`operator.mul`to multiply values together\n- Converts each character to its ASCII value using`ord(c)`\n- Uses a generator expression`(ord(c)
  for c in
  s)`to get ASCII values\n- Starts with an initial value of`1`(the identity for multiplication)\n- Returns`1`for empty strings (since there are no characters to multiply)\n\nThe function works by multiplying together all the ASCII values of the characters in the input string`s`.", 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 980, 'output_tokens': 169, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

By asking for a calculation to be done on the username, we force it to
use multiple steps:

``` python
pr = 'Use it to get the checksum of the username of this session.'
for o in chat.toolloop(pr): display(o)
```

    Looking up username

I’ll first get the username of this session, then use the checksum
function to calculate its checksum.

<details>

- id: `msg_01J8vq1FbUEE4Wufx8eBmcRB`
- content:
  `[{'citations': None, 'text': "I'll first get the username of this session, then use the checksum function to calculate its checksum.", 'type': 'text'}, {'id': 'toolu_019D16qo7yccjKkePgMY7dGH', 'input': {}, 'name': 'get_user', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1166, 'output_tokens': 59, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': 'Jeremy',
                 'tool_use_id': 'toolu_019D16qo7yccjKkePgMY7dGH',
                 'type': 'tool_result'}],
  'role': 'user'}
```

    Press Enter to execute, or enter "n" to skip?
    ```
    # Get the checksum of the username
    username = "Jeremy"
    result = checksum(username)
    print(f"Username: {username}")
    print(f"Checksum: {result}")

    # Let's also show the ASCII values being multiplied for clarity
    ascii_values = [ord(c) for c in username]
    print(f"ASCII values: {ascii_values}")
    print(f"Multiplication: {' × '.join(map(str, ascii_values))} = {result}")
    ```

Now I’ll calculate the checksum of the username “Jeremy”:

<details>

- id: `msg_01MrJGHxAqVtnPx1qZX8esp2`
- content:
  `[{'citations': None, 'text': 'Now I\'ll calculate the checksum of the username "Jeremy":', 'type': 'text'}, {'id': 'toolu_01K1BquqthoQtCzN9ANc1mau', 'input': {'code': '# Get the checksum of the username\nusername = "Jeremy"\nresult = checksum(username)\nprint(f"Username: {username}")\nprint(f"Checksum: {result}")\n\n# Let\'s also show the ASCII values being multiplied for clarity\nascii_values = [ord(c) for c in username]\nprint(f"ASCII values: {ascii_values}")\nprint(f"Multiplication: {\' × \'.join(map(str, ascii_values))} = {result}")'}, 'name': 'run_cell', 'type': 'tool_use'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `tool_use`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1238, 'output_tokens': 179, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>

``` json
{ 'content': [ { 'content': 'Username: Jeremy\n'
                            'Checksum: 1134987783204\n'
                            'ASCII values: [74, 101, 114, 101, 109, 121]\n'
                            'Multiplication: 74 × 101 × 114 × 101 × 109 × 121 '
                            '= 1134987783204\n',
                 'tool_use_id': 'toolu_01K1BquqthoQtCzN9ANc1mau',
                 'type': 'tool_result'}],
  'role': 'user'}
```

The checksum of the username “Jeremy” is **1,134,987,783,204**.

This is calculated by multiplying the ASCII values: 74 × 101 × 114 × 101
× 109 × 121 = 1,134,987,783,204.

<details>

- id: `msg_018DaJfwK2rd3nueKVYu9m6A`
- content:
  `[{'citations': None, 'text': 'The checksum of the username "Jeremy" is **1,134,987,783,204**.\n\nThis is calculated by multiplying the ASCII values: 74 × 101 × 114 × 101 × 109 × 121 = 1,134,987,783,204.', 'type': 'text'}]`
- model: `claude-sonnet-4-20250514`
- role: `assistant`
- stop_reason: `end_turn`
- stop_sequence: `None`
- type: `message`
- usage:
  `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1500, 'output_tokens': 70, 'server_tool_use': None, 'service_tier': 'standard'}`

</details>
