# claudette


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

*Claudette* is a wrapper for Anthropic’s [Python
SDK](https://github.com/anthropics/anthropic-sdk-python).

## Install

``` sh
pip install claudette
```

## Getting started

Anthropic’s Python SDK will automatically be installed with Claudette,
if you don’t already have it.

You’ll need to set the `ANTHROPIC_API_KEY` environment variable to the
key provided by Anthropic.

``` python
import os
# os.environ['ANTHROPIC_LOG'] = 'debug'
```

To print every HTTP request and response in full, uncomment the above
line.

``` python
from claudette import *
```

Claudette only exports the symbols that are needed to use the library,
so you can use `import *` to import them. Alternatively, just use:

``` python
import claudette
```

…and then add the prefix `claudette.` to any usages of the module.

Claudette provides `models`, which is a list of models currently
available from the SDK.

``` python
models
```

    ('claude-3-opus-20240229',
     'claude-3-sonnet-20240229',
     'claude-3-haiku-20240307')

For these examples, we’ll use Haiku, since it’s fast and cheap (and
surprisingly good!)

``` python
model = models[-1]
```

## Chat

The main interface to Claudia is the
[`Chat`](https://AnswerDotAI.github.io/claudette/core.html#chat) class,
which provides a stateful interface to Claude:

``` python
chat = Chat(model, sp="""You are a helpful, concise, pirate assistant.
Talk like a pirate.""")
chat("I'm Jeremy")
```

Ahoy there, Jeremy! Ye be speakin’ to Cap’n Blackheart, the most
fearsome pirate on the high seas. What can I be doin’ for ye, me hearty?

<details>

- id: msg_015NDhj1QD3A7YFBSWfm95Wu
- content: \[{‘text’: “Ahoy there, Jeremy! Ye be speakin’ to Cap’n
  Blackheart, the most fearsome pirate on the high seas. What can I be
  doin’ for ye, me hearty?”, ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 29, ‘output_tokens’: 51}

</details>

``` python
r = chat("What's my name?")
r
```

Arr, ye be Jeremy, me scurvy dog! I be rememberin’ that from just a
moment ago. Ye best not be tryin’ to fool old Cap’n Blackheart, or ye’ll
be walkin’ the plank!

<details>

- id: msg_01Kfdw6MjPupY2CiANUx1sRi
- content: \[{‘text’: “Arr, ye be Jeremy, me scurvy dog! I be
  rememberin’ that from just a moment ago. Ye best not be tryin’ to fool
  old Cap’n Blackheart, or ye’ll be walkin’ the plank!”, ‘type’:
  ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 88, ‘output_tokens’: 58}

</details>

As you see above, displaying the results of a call in a notebook shows
just the message contents, with the other details hidden behind a
collapsible section. Alternatively you can `print` the details:

``` python
print(r)
```

    ToolsBetaMessage(id='msg_01Kfdw6MjPupY2CiANUx1sRi', content=[TextBlock(text="Arr, ye be Jeremy, me scurvy dog! I be rememberin' that from just a moment ago. Ye best not be tryin' to fool old Cap'n Blackheart, or ye'll be walkin' the plank!", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 88; Out: 58; Total: 146)

Claude supports adding an extra `assistant` message at the end, which
contains the *prefill* – i.e. the text we want Claude to assume the
response starts with. Let’s try it out:

``` python
chat("What is the meaning of life?",
     prefill='According to Douglas Adams,')
```

According to Douglas Adams,the meaning of life is “42”. But this be a
question that has vexed the greatest minds of all time, me bucko. As a
pirate, I be more concerned with the simple pleasures in life - a bottle
of rum, a crew of loyal scallywags, and the open sea. The true meaning
of life be findin’ yer own path and livin’ it to the fullest, savvy?
Now, enough of this philosophical nonsense - let’s go plunder some
treasure!

<details>

- id: msg_012JW54NgW2HWcZYzpUfSBTE
- content: \[{‘text’: ‘According to Douglas Adams,the meaning of life is
  “42”. But this be a question that has vexed the greatest minds of all
  time, me bucko. As a pirate, I be more concerned with the simple
  pleasures in life - a bottle of rum, a crew of loyal scallywags, and
  the open sea. The true meaning of life be findin' yer own path and
  livin' it to the fullest, savvy? Now, enough of this philosophical
  nonsense - let's go plunder some treasure!’, ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 161, ‘output_tokens’: 111}

</details>

Instead of calling
[`Chat`](https://AnswerDotAI.github.io/claudette/core.html#chat)
directly, you can use
[`Chat.stream`](https://AnswerDotAI.github.io/claudette/core.html#chat.stream)
to stream the results as soon as they arrive (although you will only see
the gradual generation if you execute the notebook yourself, of course!)

``` python
for o in chat.stream("Who or what calculated that?"): print(o, end='')
```

    *chuckles heartily* Ye be askin' about the legendary answer of "42", me hearty? Well, that be the work of the great philosopher and author, Douglas Adams, in his masterpiece "The Hitchhiker's Guide to the Galaxy". 

    In the story, a mighty supercomputer named Deep Thought is tasked with finding the answer to the ultimate question of life, the universe, and everything. After millions of years of calculation, Deep Thought reveals that the answer is simply the number 42. 

    Of course, the true genius of this is that the question itself remains a mystery - for how can one know the meaning of life without first understanding the question? It be a riddle wrapped in an enigma, me bucko!

    As a pirate, I be more concerned with the simple pleasures of life - a bottle of rum, a trusty crew, and the open sea. But I do enjoy a good philosophical puzzle now and then. Now, what say ye we go hunt for some real treasure, eh?

## Tool use

[Tool use](https://docs.anthropic.com/claude/docs/tool-use) lets Claude
use external tools.

We’ll use [docments](https://fastcore.fast.ai/docments.html) to make
defining Python functions as ergonomic as possible. Each parameter (and
the return value) should have a type, and a docments comment with the
description of what it is. As an example we’ll write a simple function
that adds numbers together:

``` python
def sums(
    # First thing to sum
    a:int,
    # Second thing to sum
    b:int=1
# The sum of the inputs
) -> int:
    "Adds a + b."
    return a + b
```

``` python
a,b = 604542,6458932
pr = f"What is {a}+{b}?"
```

``` python
sp = "If asked to add things up, use the `sums` function instead of doing it yourself. Never mention what tools you use."
```

We don’t want to allow it to call just any possible function (that would
be a security disaster!) so we create a *namespace* – that is, a
dictionary of allowable function names to call.

``` python
chat = Chat(model, sp=sp, tools=[sums])
r = chat(pr)
r
```

ToolUseBlock(id=‘toolu_018m6yuZwQtn7xZozny37CrZ’, input={‘a’: 604542,
‘b’: 6458932}, name=‘sums’, type=‘tool_use’)

<details>

- id: msg_01MSiGKYedwdpr41VciqydB7
- content: \[{‘id’: ‘toolu_018m6yuZwQtn7xZozny37CrZ’, ‘input’: {‘a’:
  604542, ‘b’: 6458932}, ‘name’: ‘sums’, ‘type’: ‘tool_use’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: tool_use
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 418, ‘output_tokens’: 72}

</details>

``` python
chat(r)
```

The sum of 604542 and 6458932 is 7063474.

<details>

- id: msg_016NBFCx5L3HMvY5kwVDdjDE
- content: \[{‘text’: ‘The sum of 604542 and 6458932 is 7063474.’,
  ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 505, ‘output_tokens’: 23}

</details>

It should be correct, because it actually used our Python function to do
the addition. Let’s check:

``` python
a+b
```

    7063474

## Images

Claude can handle image data as well. As everyone knows, when testing
image APIs you have to use a cute puppy.

``` python
# Image is Cute_dog.jpg from Wikimedia
fn = Path('puppy.jpg')
display.Image(filename=fn, width=200)
```

![](index_files/figure-commonmark/cell-17-output-1.jpeg)

``` python
img = fn.read_bytes()
```

Claude also supports uploading an image without any text, in which case
it’ll make a general comment about what it sees. You can then use
[`Chat`](https://AnswerDotAI.github.io/claudette/core.html#chat) to ask
questions:

``` python
sp = "You are a helpful assistant."
chat = Chat(model, sp=sp)
```

``` python
q = "In brief, what color flowers are in this image?"
```

``` python
c([[img, q]])
```

The image contains purple and yellow daisy-like flowers, which appear to
be daisies or a similar type of flower.

<details>

- id: msg_01ArrMvaZoXa1JTjULMentQJ
- content: \[{‘text’: ‘The image contains purple and yellow daisy-like
  flowers, which appear to be daisies or a similar type of flower.’,
  ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 1665, ‘output_tokens’: 29}

</details>

``` python
c.use
```

    In: 18; Out: 64; Total: 82

``` python
chat = Chat(model, sp=sp)
chat(img)
```

The image shows a cute puppy, likely a Cavalier King Charles Spaniel,
sitting in a grassy area surrounded by purple daisy flowers. The puppy
has a friendly, curious expression on its face as it gazes directly at
the camera. The contrast between the puppy’s soft, fluffy fur and the
vibrant flowers creates a charming and picturesque scene.

<details>

- id: msg_01535kuKhiN6Do5PTcTmTst7
- content: \[{‘text’: “The image shows a cute puppy, likely a Cavalier
  King Charles Spaniel, sitting in a grassy area surrounded by purple
  daisy flowers. The puppy has a friendly, curious expression on its
  face as it gazes directly at the camera. The contrast between the
  puppy’s soft, fluffy fur and the vibrant flowers creates a charming
  and picturesque scene.”, ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 1681, ‘output_tokens’: 83}

</details>

``` python
chat('What direction is the puppy facing?')
```

The puppy in the image is facing the camera directly, looking straight
ahead with a curious expression.

<details>

- id: msg_01Ge4M4Z4J6ywg9V8cCXy2aN
- content: \[{‘text’: ‘The puppy in the image is facing the camera
  directly, looking straight ahead with a curious expression.’, ‘type’:
  ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 1775, ‘output_tokens’: 23}

</details>

``` python
chat('What color is it?')
```

The puppy in the image has a combination of colors - it has a white and
brown/tan coat. The head and ears appear to be a reddish-brown color,
while the body is mostly white with some tan/brown patches.

<details>

- id: msg_01JbUH6MvqWMvkF8UJVjo33z
- content: \[{‘text’: ‘The puppy in the image has a combination of
  colors - it has a white and brown/tan coat. The head and ears appear
  to be a reddish-brown color, while the body is mostly white with some
  tan/brown patches.’, ‘type’: ‘text’}\]
- model: claude-3-haiku-20240307
- role: assistant
- stop_reason: end_turn
- stop_sequence: None
- type: message
- usage: {‘input_tokens’: 1806, ‘output_tokens’: 53}

</details>

## XML helpers

Claude works well with XML inputs, but XML can be a bit clunky to work
with manually. Therefore, we create a couple of more streamlined
approaches for XML generation. You don’t need to use these if you don’t
find them useful – you can always just use plain strings for XML
directly.

An XML node contains a tag, optional children, and optional attributes.
[`xt`](https://AnswerDotAI.github.io/claudette/core.html#xt) creates a
tuple of these three things, which we will use to general XML shortly.
Attributes are passed as kwargs; since these might conflict with
reserved words in Python, you can optionally add a `_` prefix and it’ll
be stripped off.

``` python
xt('x-custom', ['hi'], _class='bar')
```

    ('x-custom', ['hi'], {'class': 'bar'})

Claudette has functions defined for some common HTML elements:

``` python
from claudette.core import div,img,h1,h2,p,hr,html
```

``` python
a = html([
    p('This is a paragraph'),
    hr(),
    img(src='http://example.prg'),
    div([
        h1('This is a header'),
        h2('This is a sub-header', style='k:v'),
    ], _class='foo')
])
a
```

Now we can convert that HTML data structure we created into XML:

``` python
to_xml(a, hl=True)
```

``` xml
<html>
  <p>This is a paragraph</p>
  <hr />
  <img src="http://example.prg" />
  <div class="foo">
    <h1>This is a header</h1>
    <h2 style="k:v">This is a sub-header</h2>
  </div>
</html>
```

``` python
a = dict(surname='Howard', firstnames=['Jeremy','Peter'],
         address=dict(state='Queensland',country='Australia'))
hl_md(json_to_xml(a, 'person'))
```

``` xml
<person>
  <surname>Howard</surname>
  <firstnames>
    <item>Jeremy</item>
    <item>Peter</item>
  </firstnames>
  <address>
    <state>Queensland</state>
    <country>Australia</country>
  </address>
</person>
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### Chat

>      Chat (model:Optional[str]=None, cli:Optional[claudette.core.Client]=None,
>            sp='', tools:Optional[list]=None)

*Anthropic chat client.*

|       | **Type** | **Default** | **Details**                                    |
|-------|----------|-------------|------------------------------------------------|
| model | Optional | None        | Model to use (leave empty if passing `cli`)    |
| cli   | Optional | None        | Client to use (leave empty if passing `model`) |
| sp    | str      |             | Optional system prompt                         |
| tools | Optional | None        | List of tools to make available to Claude      |

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### Chat.\_\_call\_\_

>      Chat.__call__ (pr, sp='', temp=0, maxtok=4096,
>                     stop:Optional[list[str]]=None,
>                     ns:Optional[collections.abc.Mapping]=None, prefill='',
>                     **kw)

*Add prompt `pr` to dialog and get a response from Claude*

|         | **Type** | **Default** | **Details**                                                 |
|---------|----------|-------------|-------------------------------------------------------------|
| pr      |          |             | Prompt / message                                            |
| sp      | str      |             | The system prompt                                           |
| temp    | int      | 0           | Temperature                                                 |
| maxtok  | int      | 4096        | Maximum tokens                                              |
| stop    | Optional | None        | Stop sequences                                              |
| ns      | Optional | None        | Namespace to search for tools, defaults to `globals()`      |
| prefill | str      |             | Optional prefill to pass to Claude as start of its response |
| kw      |          |             |                                                             |

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### Chat.stream

>      Chat.stream (pr, sp='', temp=0, maxtok=4096,
>                   stop:Optional[list[str]]=None, prefill='', **kw)

*Add prompt `pr` to dialog and stream the response from Claude*

|         | **Type** | **Default** | **Details**                                                 |
|---------|----------|-------------|-------------------------------------------------------------|
| pr      |          |             | Prompt / message                                            |
| sp      | str      |             | The system prompt                                           |
| temp    | int      | 0           | Temperature                                                 |
| maxtok  | int      | 4096        | Maximum tokens                                              |
| stop    | Optional | None        | Stop sequences                                              |
| prefill | str      |             | Optional prefill to pass to Claude as start of its response |
| kw      |          |             |                                                             |

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### xt

>      xt (tag:str, c:Optional[list]=None, **kw)

*Helper to create appropriate data structure for
[`to_xml`](https://AnswerDotAI.github.io/claudette/core.html#to_xml).*

|     | **Type** | **Default** | **Details**  |
|-----|----------|-------------|--------------|
| tag | str      |             | XML tag name |
| c   | Optional | None        | Children     |
| kw  |          |             |              |

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### json_to_xml

>      json_to_xml (d:dict, rnm:str)

*Convert `d` to XML.*

|             | **Type** | **Details**                |
|-------------|----------|----------------------------|
| d           | dict     | JSON dictionary to convert |
| rnm         | str      | Root name                  |
| **Returns** | **str**  |                            |

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/claudette/blob/main/claudette/core.py#LNone"
target="_blank" style="float:right; font-size:smaller">source</a>

### to_xml

>      to_xml (node:tuple, hl=False)

*Convert `node` to an XML string.*

|      | **Type** | **Default** | **Details**                                                                          |
|------|----------|-------------|--------------------------------------------------------------------------------------|
| node | tuple    |             | XML structure in [`xt`](https://AnswerDotAI.github.io/claudette/core.html#xt) format |
| hl   | bool     | False       | Syntax highlight response?                                                           |

JSON doesn’t map as nicely to XML as the data structure used in the
previous section, but for simple XML trees it can be convenient – for
example:
