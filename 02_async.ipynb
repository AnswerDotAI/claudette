{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp asink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# The async version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect, typing, mimetypes, base64, json\n",
    "from collections import abc\n",
    "try: from IPython import display\n",
    "except: display=None\n",
    "\n",
    "from anthropic import AsyncAnthropic\n",
    "from anthropic.types import ToolUseBlock\n",
    "from toolslm.funccall import get_schema, mk_ns, call_func\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.utils import *\n",
    "from claudette.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13866a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## Async SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b53a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[1]\n",
    "cli = AsyncAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec40731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Jeremy! Nice to meet you. I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01UBPA1yCoPZdk4vDbCwdXGm`\n",
       "- content: `[{'text': \"Hi Jeremy! Nice to meet you. I'm Claude, an AI assistant created by Anthropic. How can I help you today?\", 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 10, 'output_tokens': 31}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01UBPA1yCoPZdk4vDbCwdXGm', content=[TextBlock(text=\"Hi Jeremy! Nice to meet you. I'm Claude, an AI assistant created by Anthropic. How can I help you today?\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 10; Out: 31; Cache create: 0; Cache read: 0; Total: 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = await cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AsyncClient(Client):\n",
    "    def __init__(self, model, cli=None, log=False):\n",
    "        \"Async Anthropic messages client.\"\n",
    "        super().__init__(model,cli,log)\n",
    "        if not cli: self.c = AsyncAnthropic(default_headers={'anthropic-beta': 'prompt-caching-2024-07-31'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01e9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = AsyncClient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0181f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 10; Out: 31; Cache create: 0; Cache read: 0; Total: 41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6520a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _stream(self:AsyncClient, msgs:list, prefill='', **kwargs):\n",
    "    async with self.c.messages.stream(model=self.model, messages=mk_msgs(msgs), **kwargs) as s:\n",
    "        if prefill: yield prefill\n",
    "        async for o in s.text_stream: yield o\n",
    "        self._log(await s.get_final_message(), prefill, msgs, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "835638bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Client)\n",
    "async def __call__(self:AsyncClient,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp='', # The system prompt\n",
    "             temp=0, # Temperature\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             prefill='', # Optional prefill to pass to Claude as start of its response\n",
    "             stream:bool=False, # Stream response?\n",
    "             stop=None, # Stop sequence\n",
    "             tools:Optional[list]=None, # List of tools to make available to Claude\n",
    "             tool_choice:Optional[dict]=None, # Optionally force use of some tool\n",
    "             **kwargs):\n",
    "    \"Make an async call to Claude.\"\n",
    "    if tools: kwargs['tools'] = [get_schema(o) for o in listify(tools)]\n",
    "    if tool_choice: kwargs['tool_choice'] = mk_tool_choice(tool_choice)\n",
    "    msgs = self._precall(msgs, prefill, stop, kwargs)\n",
    "    if stream: return self._stream(msgs, prefill=prefill, max_tokens=maxtok, system=sp, temperature=temp, **kwargs)\n",
    "    res = await self.c.messages.create(\n",
    "        model=self.model, messages=msgs, max_tokens=maxtok, system=sp, temperature=temp, **kwargs)\n",
    "    return self._log(res, prefill, msgs, maxtok, sp, temp, stream=stream, stop=stop, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881b5e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Cache create: 0; Cache read: 0; Total: 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = AsyncClient(model, log=True)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1220856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01TC5wq1bS1ZcJMopq8bZ4o2`\n",
       "- content: `[{'text': 'Hello! How can I help you today?', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 8, 'output_tokens': 12, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01TC5wq1bS1ZcJMopq8bZ4o2', content=[TextBlock(text='Hello! How can I help you today?', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 8; Out: 12; Cache create: 0; Cache read: 0; Total: 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.model = models[1]\n",
    "await c('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae9f7e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 12; Cache create: 0; Cache read: 0; Total: 20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f479429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to Douglas Adams,  it's 42. More seriously, there's no universal answer - it's deeply personal. Common perspectives include: finding happiness, creating meaning through relationships and achievements, pursuing knowledge, helping others, or following spiritual/religious beliefs.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_012ZvrAoNyBherFi2q4fDRWq`\n",
       "- content: `[{'text': \"According to Douglas Adams,  it's 42. More seriously, there's no universal answer - it's deeply personal. Common perspectives include: finding happiness, creating meaning through relationships and achievements, pursuing knowledge, helping others, or following spiritual/religious beliefs.\", 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 24, 'output_tokens': 50, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_012ZvrAoNyBherFi2q4fDRWq', content=[TextBlock(text=\"According to Douglas Adams,  it's 42. More seriously, there's no universal answer - it's deeply personal. Common perspectives include: finding happiness, creating meaning through relationships and achievements, pursuing knowledge, helping others, or following spiritual/religious beliefs.\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 24; Out: 50; Cache create: 0; Cache read: 0; Total: 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Concisely, what is the meaning of life?\"\n",
    "pref = 'According to Douglas Adams,'\n",
    "await c(q, prefill=pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0230a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?"
     ]
    }
   ],
   "source": [
    "async for o in (await c('Hi', stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beb25f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 40; Out: 74; Cache create: 0; Cache read: 0; Total: 114"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db1c75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Douglas Adams,  it's 42. More seriously, there's no universal answer - it's deeply personal. Common perspectives include: finding happiness, creating meaning through relationships and achievements, pursuing knowledge, helping others, or following spiritual/religious beliefs."
     ]
    }
   ],
   "source": [
    "async for o in (await c(q, prefill=pref, stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e36eddc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 64; Out: 124; Cache create: 0; Cache read: 0; Total: 188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int=1 # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d51f2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "sp = \"You are a summing expert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff81d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[get_schema(sums)]\n",
    "choice = mk_tool_choice('sums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7292b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sum of 604542 and 6458932 is 7063474.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(pr)\n",
    "r = await c(msgs, sp=sp, tools=sums, tool_choice=sums)\n",
    "tr = mk_toolres(r, ns=globals())\n",
    "msgs += tr\n",
    "contents(await c(msgs, sp=sp, tools=sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bae7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [get_schema(sums)]\n",
    "# msgs = mk_msgs(pr)\n",
    "# r = await c(msgs, sp=sp, tools=tools, tool_choice=choice)\n",
    "# tr = mk_toolres(r, ns=globals())\n",
    "# msgs += tr\n",
    "# contents(await c(msgs, sp=sp, tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7af80",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "@delegates(Client.__call__)\n",
    "async def structured(self:AsyncClient,\n",
    "               msgs:list, # List of messages in the dialog\n",
    "               tools:Optional[list]=None, # List of tools to make available to Claude\n",
    "               obj:Optional=None, # Class to search for tools  \n",
    "               ns:Optional[abc.Mapping]=None, # Namespace to search for tools\n",
    "               **kwargs):\n",
    "    \"Return the value of all tool calls (generally used for structured outputs)\"\n",
    "    tools = listify(tools)\n",
    "    if ns is None: ns=mk_ns(*tools)\n",
    "    if obj is not None: ns = mk_ns(obj)\n",
    "    res = await self(msgs, tools=tools, tool_choice=tools,**kwargs)\n",
    "    cts = getattr(res, 'content', [])\n",
    "    tcs = [call_func(o.name, o.input, ns=ns) for o in cts if isinstance(o,ToolUseBlock)]\n",
    "    return tcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a71b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7063474]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await c.structured(pr, sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea144b8",
   "metadata": {},
   "source": [
    "## AsyncChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a77d1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@delegates()\n",
    "class AsyncChat(Chat):\n",
    "    def __init__(self,\n",
    "                 model:Optional[str]=None, # Model to use (leave empty if passing `cli`)\n",
    "                 cli:Optional[Client]=None, # Client to use (leave empty if passing `model`)\n",
    "                 **kwargs):\n",
    "        \"Anthropic async chat client.\"\n",
    "        super().__init__(model, cli, **kwargs)\n",
    "        if not cli: self.c = AsyncClient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04b837c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Cache create: 0; Cache read: 0; Total: 0, [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"Never mention what tools you use.\"\n",
    "chat = AsyncChat(model, sp=sp)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a05df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _stream(self:AsyncChat, res):\n",
    "    async for o in res: yield o\n",
    "    self.h += mk_toolres(self.c.result, ns=self.tools, obj=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e5ab3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _append_pr(self:AsyncChat, pr=None):\n",
    "    prev_role = nested_idx(self.h, -1, 'role') if self.h else 'assistant' # First message should be 'user' if no history\n",
    "    if pr and prev_role == 'user': await self()\n",
    "    self._post_pr(pr, prev_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bec85e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def __call__(self:AsyncChat,\n",
    "        pr=None,  # Prompt / message\n",
    "        temp=0, # Temperature\n",
    "        maxtok=4096, # Maximum tokens\n",
    "        stream=False, # Stream response?\n",
    "        prefill='', # Optional prefill to pass to Claude as start of its response\n",
    "        **kw):\n",
    "    await self._append_pr(pr)\n",
    "    res = await self.c(self.h, stream=stream, prefill=prefill, sp=self.sp, temp=temp, maxtok=maxtok, **kw)\n",
    "    if stream: return self._stream(res)\n",
    "    self.h += mk_toolres(self.c.result, ns=mk_ns(*listify(self.tools)), obj=self)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40073f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Jeremy.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01BNxuSzZGanZupYuJxFDTgi`\n",
       "- content: `[{'text': 'Your name is Jeremy.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 41, 'output_tokens': 8, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01BNxuSzZGanZupYuJxFDTgi', content=[TextBlock(text='Your name is Jeremy.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 41; Out: 8; Cache create: 0; Cache read: 0; Total: 49)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat(\"I'm Jeremy\")\n",
    "await chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20a32de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to Douglas Adams,  42. But more seriously: to find purpose, create meaning, love, grow, and make a positive impact during our time here.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_012WB8YcoMyPk2Uuh69eUxnF`\n",
       "- content: `[{'text': 'According to Douglas Adams,  42. But more seriously: to find purpose, create meaning, love, grow, and make a positive impact during our time here.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 69, 'output_tokens': 31, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_012WB8YcoMyPk2Uuh69eUxnF', content=[TextBlock(text='According to Douglas Adams,  42. But more seriously: to find purpose, create meaning, love, grow, and make a positive impact during our time here.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 69; Out: 31; Cache create: 0; Cache read: 0; Total: 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Concisely, what is the meaning of life?\"\n",
    "pref = 'According to Douglas Adams,'\n",
    "await chat(q, prefill=pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "529104ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeremy! Nice to meet you. How are you today?"
     ]
    }
   ],
   "source": [
    "chat = AsyncChat(model, sp=sp)\n",
    "async for o in (await chat(\"I'm Jeremy\", stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee6535cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "7,063,474\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_013c9kT2obX52nLMf9PmWWHH`\n",
       "- content: `[{'text': '7,063,474', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 24, 'output_tokens': 9, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_013c9kT2obX52nLMf9PmWWHH', content=[TextBlock(text='7,063,474', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 24; Out: 9; Cache create: 0; Cache read: 0; Total: 33)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "chat = AsyncChat(model, sp=sp, tools=[sums])\n",
    "r = await chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dc85163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sum of 604,542 and 6,458,932 is 7,063,474.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01F6Jms2nhe8VEDN16ZUGomv`\n",
       "- content: `[{'text': 'The sum of 604,542 and 6,458,932 is 7,063,474.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 31, 'output_tokens': 27, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01F6Jms2nhe8VEDN16ZUGomv', content=[TextBlock(text='The sum of 604,542 and 6,458,932 is 7,063,474.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 31; Out: 27; Cache create: 0; Cache read: 0; Total: 58)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr += \"Say the answer in a sentence.\"\n",
    "chat = AsyncChat(model, sp=sp, tools=[sums])\n",
    "r = await chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d35d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = Path('samples/puppy.jpg')\n",
    "img = fn.read_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c0eed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In this adorable puppy photo, there are purple/lavender colored flowers (appears to be asters or similar daisy-like flowers) in the background.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01MLGBSn2QYJoKnthg7W2Tkj`\n",
       "- content: `[{'text': 'In this adorable puppy photo, there are purple/lavender colored flowers (appears to be asters or similar daisy-like flowers) in the background.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 110, 'output_tokens': 37, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01MLGBSn2QYJoKnthg7W2Tkj', content=[TextBlock(text='In this adorable puppy photo, there are purple/lavender colored flowers (appears to be asters or similar daisy-like flowers) in the background.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 110; Out: 37; Cache create: 0; Cache read: 0; Total: 147)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"In brief, what color flowers are in this image?\"\n",
    "msg = mk_msg([img, q])\n",
    "await c([msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
