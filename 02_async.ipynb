{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp asink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# The async version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect, typing, mimetypes, base64, json\n",
    "from collections import abc\n",
    "try: from IPython import display\n",
    "except: display=None\n",
    "\n",
    "from anthropic import AsyncAnthropic\n",
    "from toolslm.funccall import get_schema\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.utils import *\n",
    "from claudette.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13866a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## Async SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b53a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[1]\n",
    "cli = AsyncAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec40731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Jeremy! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to talk about or any questions you have?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_019gsEQs5dqb3kgwNJbTH27M`\n",
       "- content: `[{'text': \"Hello Jeremy! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to talk about or any questions you have?\", 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 10, 'output_tokens': 36}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_019gsEQs5dqb3kgwNJbTH27M', content=[TextBlock(text=\"Hello Jeremy! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to talk about or any questions you have?\", type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 10; Out: 36; Total: 46)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = await cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AsyncClient(Client):\n",
    "    def __init__(self, model, cli=None, log=False):\n",
    "        \"Async Anthropic messages client.\"\n",
    "        super().__init__(model,cli,log)\n",
    "        if not cli: self.c = AsyncAnthropic(default_headers={'anthropic-beta': 'prompt-caching-2024-07-31'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = AsyncClient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 10; Out: 36; Total: 46"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _stream(self:AsyncClient, msgs:list, prefill='', **kwargs):\n",
    "    async with self.c.messages.stream(model=self.model, messages=mk_msgs(msgs), **kwargs) as s:\n",
    "        if prefill: yield prefill\n",
    "        async for o in s.text_stream: yield o\n",
    "        self._log(await s.get_final_message(), prefill, msgs, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835638bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Client)\n",
    "async def __call__(self:AsyncClient,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp='', # The system prompt\n",
    "             temp=0, # Temperature\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             prefill='', # Optional prefill to pass to Claude as start of its response\n",
    "             stream:bool=False, # Stream response?\n",
    "             stop=None, # Stop sequence\n",
    "             **kwargs):\n",
    "    \"Make an async call to Claude.\"\n",
    "    msgs = self._precall(msgs, prefill, stop, kwargs)\n",
    "    if stream: return self._stream(msgs, prefill=prefill, max_tokens=maxtok, system=sp, temperature=temp, **kwargs)\n",
    "    res = await self.c.messages.create(\n",
    "        model=self.model, messages=msgs, max_tokens=maxtok, system=sp, temperature=temp, **kwargs)\n",
    "    return self._log(res, prefill, msgs, maxtok, sp, temp, stream=stream, stop=stop, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b5e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = AsyncClient(model, log=True)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1220856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01L9vqP9r1LcmvSk8vWGLbPo`\n",
       "- content: `[{'text': 'Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 8, 'output_tokens': 29, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01L9vqP9r1LcmvSk8vWGLbPo', content=[TextBlock(text='Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything.', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 8; Out: 29; Total: 37)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.model = models[1]\n",
    "await c('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 29; Total: 37"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f479429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon meaning of life. Many philosophers and religions have proposed different answers, but it remains an open question that individuals must grapple with for themselves.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01KAJbCneA2oCRPVm9EkyDXF`\n",
       "- content: `[{'text': \"According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon meaning of life. Many philosophers and religions have proposed different answers, but it remains an open question that individuals must grapple with for themselves.\", 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 24, 'output_tokens': 51, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01KAJbCneA2oCRPVm9EkyDXF', content=[TextBlock(text=\"According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon meaning of life. Many philosophers and religions have proposed different answers, but it remains an open question that individuals must grapple with for themselves.\", type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 24; Out: 51; Total: 75)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Concisely, what is the meaning of life?\"\n",
    "pref = 'According to Douglas Adams,'\n",
    "await c(q, prefill=pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0230a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything."
     ]
    }
   ],
   "source": [
    "async for o in (await c('Hi', stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb25f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 40; Out: 109; Total: 149"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon meaning of life. Many philosophers and religions have proposed different answers, but it remains an open question that individuals must grapple with for themselves."
     ]
    }
   ],
   "source": [
    "async for o in (await c(q, prefill=pref, stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36eddc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 64; Out: 160; Total: 224"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int=1 # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "sp = \"You are a summing expert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff81d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[get_schema(sums)]\n",
    "choice = mk_tool_choice('sums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae7694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As a summing expert, I\\'m happy to help you with this addition. The sum of 604542 and 6458932 is 7063474.\\n\\nTo break it down:\\n604542 (first number)\\n+ 6458932 (second number)\\n= 7063474 (total sum)\\n\\nThis result was calculated using the \"sums\" function, which adds two numbers together. Is there anything else you\\'d like me to sum for you?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [get_schema(sums)]\n",
    "msgs = mk_msgs(pr)\n",
    "r = await c(msgs, sp=sp, tools=tools, tool_choice=choice)\n",
    "tr = mk_toolres(r, ns=globals())\n",
    "msgs += tr\n",
    "contents(await c(msgs, sp=sp, tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea144b8",
   "metadata": {},
   "source": [
    "## AsyncChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@delegates()\n",
    "class AsyncChat(Chat):\n",
    "    def __init__(self,\n",
    "                 model:Optional[str]=None, # Model to use (leave empty if passing `cli`)\n",
    "                 cli:Optional[Client]=None, # Client to use (leave empty if passing `model`)\n",
    "                 **kwargs):\n",
    "        \"Anthropic async chat client.\"\n",
    "        super().__init__(model, cli, **kwargs)\n",
    "        if not cli: self.c = AsyncClient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b837c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Total: 0, [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"Never mention what tools you use.\"\n",
    "chat = AsyncChat(model, sp=sp)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a05df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _stream(self:AsyncChat, res):\n",
    "    async for o in res: yield o\n",
    "    self.h += mk_toolres(self.c.result, ns=self.tools, obj=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ab3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def _append_pr(self:AsyncChat, pr=None):\n",
    "    prev_role = nested_idx(self.h, -1, 'role') if self.h else 'assistant' # First message should be 'user' if no history\n",
    "    if pr and prev_role == 'user': await self()\n",
    "    self._post_pr(pr, prev_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec85e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "async def __call__(self:AsyncChat,\n",
    "        pr=None,  # Prompt / message\n",
    "        temp=0, # Temperature\n",
    "        maxtok=4096, # Maximum tokens\n",
    "        stream=False, # Stream response?\n",
    "        prefill='', # Optional prefill to pass to Claude as start of its response\n",
    "        **kw):\n",
    "    await self._append_pr(pr)\n",
    "    if self.tools: kw['tools'] = [get_schema(o) for o in self.tools]\n",
    "    res = await self.c(self.h, stream=stream, prefill=prefill, sp=self.sp, temp=temp, maxtok=maxtok, **kw)\n",
    "    if stream: return self._stream(res)\n",
    "    self.h += mk_toolres(self.c.result, ns=self.tools, obj=self)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40073f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Jeremy, as you mentioned in your previous message.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01NMugMXWpDP9iuTXeLkHarn`\n",
       "- content: `[{'text': 'Your name is Jeremy, as you mentioned in your previous message.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 64, 'output_tokens': 16, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01NMugMXWpDP9iuTXeLkHarn', content=[TextBlock(text='Your name is Jeremy, as you mentioned in your previous message.', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 64; Out: 16; Total: 80)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat(\"I'm Jeremy\")\n",
    "await chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a32de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon answer. Common philosophical perspectives include:\n",
       "\n",
       "1. Finding personal fulfillment\n",
       "2. Serving others\n",
       "3. Pursuing happiness\n",
       "4. Creating meaning through our choices\n",
       "5. Experiencing and appreciating existence\n",
       "\n",
       "Ultimately, many believe each individual must determine their own life's meaning.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01VPWUQn5Do1Kst8RYUDQvCu`\n",
       "- content: `[{'text': \"According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon answer. Common philosophical perspectives include:\\n\\n1. Finding personal fulfillment\\n2. Serving others\\n3. Pursuing happiness\\n4. Creating meaning through our choices\\n5. Experiencing and appreciating existence\\n\\nUltimately, many believe each individual must determine their own life's meaning.\", 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 100, 'output_tokens': 82, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01VPWUQn5Do1Kst8RYUDQvCu', content=[TextBlock(text=\"According to Douglas Adams,  the meaning of life is 42. More seriously, there's no universally agreed upon answer. Common philosophical perspectives include:\\n\\n1. Finding personal fulfillment\\n2. Serving others\\n3. Pursuing happiness\\n4. Creating meaning through our choices\\n5. Experiencing and appreciating existence\\n\\nUltimately, many believe each individual must determine their own life's meaning.\", type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 100; Out: 82; Total: 182)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Concisely, what is the meaning of life?\"\n",
    "pref = 'According to Douglas Adams,'\n",
    "await chat(q, prefill=pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529104ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeremy! It's nice to meet you. How are you doing today? Is there anything in particular you'd like to chat about or any questions I can help you with?"
     ]
    }
   ],
   "source": [
    "chat = AsyncChat(model, sp=sp)\n",
    "async for o in (await chat(\"I'm Jeremy\", stream=True)): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6535cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To answer this question, I can use the \"sums\" function to add these two numbers together. Let me do that for you.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_015z1rffSWFxvj7rSpzc43ZE`\n",
       "- content: `[{'text': 'To answer this question, I can use the \"sums\" function to add these two numbers together. Let me do that for you.', 'type': 'text'}, {'id': 'toolu_01SNKhtfnDQBC4RGY4mUCq1v', 'input': {'a': 604542, 'b': 6458932}, 'name': 'sums', 'type': 'tool_use'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `tool_use`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 428, 'output_tokens': 101, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_015z1rffSWFxvj7rSpzc43ZE', content=[TextBlock(text='To answer this question, I can use the \"sums\" function to add these two numbers together. Let me do that for you.', type='text'), ToolUseBlock(id='toolu_01SNKhtfnDQBC4RGY4mUCq1v', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 428; Out: 101; Total: 529)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "chat = AsyncChat(model, sp=sp, tools=[sums])\n",
    "r = await chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sum of 604542 and 6458932 is 7063474.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_018KAsE2YGiXWjUJkLPrXpb2`\n",
       "- content: `[{'text': 'The sum of 604542 and 6458932 is 7063474.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 543, 'output_tokens': 23, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_018KAsE2YGiXWjUJkLPrXpb2', content=[TextBlock(text='The sum of 604542 and 6458932 is 7063474.', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 543; Out: 23; Total: 566)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = Path('samples/puppy.jpg')\n",
    "img = fn.read_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0eed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The flowers in this image are purple. They appear to be small, daisy-like flowers, possibly asters or some type of purple daisy, blooming in the background behind the adorable puppy in the foreground.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_017qgZggLjUY915mWbWCkb9X`\n",
       "- content: `[{'text': 'The flowers in this image are purple. They appear to be small, daisy-like flowers, possibly asters or some type of purple daisy, blooming in the background behind the adorable puppy in the foreground.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20240620`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'input_tokens': 110, 'output_tokens': 50, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_017qgZggLjUY915mWbWCkb9X', content=[TextBlock(text='The flowers in this image are purple. They appear to be small, daisy-like flowers, possibly asters or some type of purple daisy, blooming in the background behind the adorable puppy in the foreground.', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 110; Out: 50; Total: 160)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"In brief, what color flowers are in this image?\"\n",
    "msg = mk_msg([img, q])\n",
    "await c([msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
