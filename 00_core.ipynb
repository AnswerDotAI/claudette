{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Claudio source code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82cc7ff",
   "metadata": {},
   "source": [
    "This is the 'literate' source code for Claudio. You can view the fully rendered version of the notebook [here](https://answerdotai.github.io/claudio/core.html), or you can clone the git repo and run the [interactive notebook](https://github.com/AnswerDotAI/claudio/blob/main/00_core.ipynb) in Jupyter. The notebook is converted the [Python module claudio/core.py](https://github.com/AnswerDotAI/claudio/blob/main/claudio/core.py) using [nbdev](https://nbdev.fast.ai/). The goal of this source code is to both create the Python module, and also to teach the reader *how* it is created, without assuming much existing knowledge about Claude's API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad998e-4bb1-4bed-abf4-6e8606cb2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['ANTHROPIC_LOG'] = 'debug'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0a3d1",
   "metadata": {},
   "source": [
    "To print every HTTP request and response in full, uncomment the above line. This functionality is provided by Anthropic's SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tokenize, ast, inspect, inspect, typing\n",
    "import xml.etree.ElementTree as ET, json\n",
    "from collections import abc\n",
    "\n",
    "from anthropic import Anthropic\n",
    "from anthropic.types import Usage, TextBlock, Message\n",
    "from anthropic.types.beta.tools import ToolsBetaMessage, tool_use_block\n",
    "from inspect import Parameter\n",
    "from io import BytesIO\n",
    "try: from IPython.display import Markdown,HTML\n",
    "except: Markdown,HTML=None,None\n",
    "\n",
    "from fastcore.docments import docments\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "models = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cff615",
   "metadata": {},
   "source": [
    "These are the current versions of Anthropic's model at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "empty = Parameter.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff33681",
   "metadata": {},
   "source": [
    "For examples, we'll use Haiku, since it's fast and cheap (and surprisingly good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## Antropic SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d79ed",
   "metadata": {},
   "source": [
    "This is what Anthropic's SDK provides for interacting with Python. To use it, pass it a list of *messages*, with *content* and a *role*. The roles should alternate between *user* and *assistant*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d514f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_014HjqFL5CM3dZ1z98nnh2f6', content=[TextBlock(text=\"It's nice to meet you Jeremy! I'm Claude, an AI assistant created by Anthropic. I'm here to help out however I can. Please let me know if you have any questions or if there is anything I can assist you with.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=10, output_tokens=54))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a87f77",
   "metadata": {},
   "source": [
    "Now we're going to write our first function which will be included to the `claudia/core.py` module. In the rendered version of the notebook, for each exported function you'll see 3 things, in this order:\n",
    "\n",
    "- The source code\n",
    "- The signature\n",
    "- The doc string.\n",
    "\n",
    "After that, we'll generally provide a bit more detail on what we've created, and why, along with a sample usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_msg(content, role='user', **kw):\n",
    "    \"Helper to create a `dict` appropriate for a Claude message\"\n",
    "    if hasattr(content, 'content'): content,role = content.content,content.role\n",
    "    if isinstance(content, abc.Mapping): content=content['content']\n",
    "    return dict(role=role, content=content, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cf2b1",
   "metadata": {},
   "source": [
    "We make things a bit more convenient by writing a function to create these messages for us.\n",
    "\n",
    "As you see from the source, `mk_msg` doesn't only handle `str` for `content`, but can also deal with a `dict` or an object containing `content` (such as for from assistant responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfa576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': \"I'm Jeremy\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'm Jeremy\"\n",
    "m = mk_msg(prompt)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae65254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01JW2U8pDjrbPPqoq9rjqzNv', content=[TextBlock(text=\"It's nice to meet you Jeremy! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know how I can be of assistance.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=10, output_tokens=47))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a291127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_block(r, blk_type=TextBlock):\n",
    "    \"Find the first block of type `blk_type` in `r.content`\"\n",
    "    return first(o for o in r.content if isinstance(o,blk_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ef1e9",
   "metadata": {},
   "source": [
    "This makes it easier to grab the needed parts of Claude's responses, which can include multiple pieces of content. By default, we look for the first text block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adec146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlock(text=\"It's nice to meet you Jeremy! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know how I can be of assistance.\", type='text')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_block(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971592e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def contents(r):\n",
    "    \"Helper to get the contents from Claude response `r`\"\n",
    "    blk = find_block(r)\n",
    "    if not blk: blk = r.content[0]\n",
    "    return blk.text.strip() if hasattr(blk,'text') else blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b19498",
   "metadata": {},
   "source": [
    "For display purposes, we often just want to show the text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f28c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you Jeremy! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know how I can be of assistance.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_msgs(msgs, **kw):\n",
    "    \"Helper to set 'assistant' role on alternate messages\"\n",
    "    if isinstance(msgs,str): msgs=[msgs]\n",
    "    return [mk_msg(o, ('user','assistant')[i%2], **kw) for i,o in enumerate(msgs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d1b1a",
   "metadata": {},
   "source": [
    "LLMs, including Claude, don't actually have state, but instead dialogs are created by passing back all previous prompts and responses every time. With Claude, they always alternate *user* and *assistant*. Therefore we create a function to make it easier to build up these dialog lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72853827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Jeremy\"},\n",
       " {'role': 'assistant',\n",
       "  'content': [TextBlock(text=\"It's nice to meet you Jeremy! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know how I can be of assistance.\", type='text')]},\n",
       " {'role': 'user', 'content': 'I forgot my name. Can you remind me please?'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs([prompt, r, 'I forgot my name. Can you remind me please?'])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56aaac0",
   "metadata": {},
   "source": [
    "Now, if we pass this list of messages to Claude, the model treats it as a conversation to respond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1f21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01QU9shSR6KX5knJgzq7rDxf', content=[TextBlock(text=\"I do not actually know your name - you said earlier that your name is Jeremy, but if you've now forgotten that, I don't have any other information about your name. As an AI assistant, I don't have access to personal details about you unless you provide them to me directly. If you're unsure of your own name, I'd suggest trying to recall it or referring to other sources that may have that information.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=71, output_tokens=90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.messages.create(messages=msgs, model=model, max_tokens=200)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _repr_html_(self:(ToolsBetaMessage,Message)):\n",
    "    det = '</li>\\n<li>'.join(f'{k}: {v}' for k,v in self.dict().items())\n",
    "    return f\"\"\"{contents(self)}\n",
    "<details><ul><li>\n",
    "{det}\n",
    "</ul></li></details>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e534c85",
   "metadata": {},
   "source": [
    "Jupyter looks for a `_repr_html_` method in displayed objects; we add this in order to display just the content text, and collapse full details into a hideable section. Note that `patch` is from `fastcore`, and is used to add (or replace) functionality in an existing class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cff05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "I do not actually know your name - you said earlier that your name is Jeremy, but if you've now forgotten that, I don't have any other information about your name. As an AI assistant, I don't have access to personal details about you unless you provide them to me directly. If you're unsure of your own name, I'd suggest trying to recall it or referring to other sources that may have that information.\n",
       "<details><ul><li>\n",
       "id: msg_01QU9shSR6KX5knJgzq7rDxf</li>\n",
       "<li>content: [{'text': \"I do not actually know your name - you said earlier that your name is Jeremy, but if you've now forgotten that, I don't have any other information about your name. As an AI assistant, I don't have access to personal details about you unless you provide them to me directly. If you're unsure of your own name, I'd suggest trying to recall it or referring to other sources that may have that information.\", 'type': 'text'}]</li>\n",
       "<li>model: claude-3-haiku-20240307</li>\n",
       "<li>role: assistant</li>\n",
       "<li>stop_reason: end_turn</li>\n",
       "<li>stop_sequence: None</li>\n",
       "<li>type: message</li>\n",
       "<li>usage: {'input_tokens': 71, 'output_tokens': 90}\n",
       "</ul></li></details>"
      ],
      "text/plain": [
       "Message(id='msg_01QU9shSR6KX5knJgzq7rDxf', content=[TextBlock(text=\"I do not actually know your name - you said earlier that your name is Jeremy, but if you've now forgotten that, I don't have any other information about your name. As an AI assistant, I don't have access to personal details about you unless you provide them to me directly. If you're unsure of your own name, I'd suggest trying to recall it or referring to other sources that may have that information.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=71, output_tokens=90))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30ffcf",
   "metadata": {},
   "source": [
    "One key part of the response is the `usage` key, which tells us how many tokens we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=71, output_tokens=90)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dee121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, out=0):\n",
    "    \"Slightly more concise version of `Usage`\"\n",
    "    return Usage(input_tokens=inp, output_tokens=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badc9b9",
   "metadata": {},
   "source": [
    "The constructor provided by Anthropic is rather verbose, so we clean it up a bit, using a lowercase version of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=5, output_tokens=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch(as_prop=True)\n",
    "def total(self:Usage): return self.input_tokens+self.output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11007e9f",
   "metadata": {},
   "source": [
    "Adding a `total` property to `Usage` makes it easier to see how many tokens we've used up altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce6464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5,1).total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:Usage): return f'In: {self.input_tokens}; Out: {self.output_tokens}; Total: {self.total}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453b1eb",
   "metadata": {},
   "source": [
    "In python, patching `__repr__` let's us change how an object is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacdd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 71; Out: 90; Total: 161"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:Usage, b):\n",
    "    return usage(self.input_tokens+b.input_tokens, self.output_tokens+b.output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0c3e1",
   "metadata": {},
   "source": [
    "And, patching `__add__` let's make `+` work on a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2f1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 142; Out: 180; Total: 322"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage+r.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace28f3e",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad385e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None):\n",
    "        \"Basic Anthropic messages client\"\n",
    "        self.model,self.use = model,Usage(input_tokens=0,output_tokens=0)\n",
    "        self.c = (cli or Anthropic())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed7d11",
   "metadata": {},
   "source": [
    "We'll create a simple `Client` for `Anthropic` which tracks usage stores the model to use. We don't add any methods right away -- instead we'll use `patch` for that so we can add and document them incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bf191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(model)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9621c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r:ToolsBetaMessage):\n",
    "    \"Store the result of the message and accrue total usage\"\n",
    "    self.result = r\n",
    "    self.use += r.usage\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a5268",
   "metadata": {},
   "source": [
    "We use a `_` prefix on private methods, but we document them here in the interests of literate source code.\n",
    "\n",
    "`_r` will be used each time we get a new result, to track usage and also to keep the result available for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14553ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 71; Out: 90; Total: 161"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __call__(self:Client, msgs, sp='', temp=0, maxtok=4096, stop=None, **kw):\n",
    "    \"Make a call to Claude without streaming\"\n",
    "    r = self.c.beta.tools.messages.create(\n",
    "        model=self.model, messages=mk_msgs(msgs), max_tokens=maxtok, system=sp, temperature=temp, stop_sequences=stop, **kw)\n",
    "    return self._r(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95be13",
   "metadata": {},
   "source": [
    "Defining `__call__` let's us use an object like a function (i.e it's *callable*). We use it as a small wrapper over `messages.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1da14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Hello! How can I assist you today?\n",
       "<details><ul><li>\n",
       "id: msg_01XKoCB5Zg82ntkA6CHQ5Gve</li>\n",
       "<li>content: [{'text': 'Hello! How can I assist you today?', 'type': 'text'}]</li>\n",
       "<li>model: claude-3-haiku-20240307</li>\n",
       "<li>role: assistant</li>\n",
       "<li>stop_reason: end_turn</li>\n",
       "<li>stop_sequence: None</li>\n",
       "<li>type: message</li>\n",
       "<li>usage: {'input_tokens': 8, 'output_tokens': 12}\n",
       "</ul></li></details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01XKoCB5Zg82ntkA6CHQ5Gve', content=[TextBlock(text='Hello! How can I assist you today?', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 8; Out: 12; Total: 20)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12e1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 79; Out: 102; Total: 181"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def stream(self:Client, msgs, sp='', temp=0, maxtok=4096, stop=None, **kw):\n",
    "    \"Make a call to Claude, streaming the result\"\n",
    "    with self.c.messages.stream(model=self.model, messages=mk_msgs(msgs), max_tokens=maxtok,\n",
    "                                system=sp, temperature=temp, stop_sequences=stop, **kw) as s:\n",
    "        yield from s.text_stream\n",
    "        return self._r(s.get_final_message())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb2ee4",
   "metadata": {},
   "source": [
    "We also define a wrapper over `messages.stream`, which is like `messages.create`, but streams the response back incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "for o in c.stream('Hi'): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb25f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 87; Out: 114; Total: 201"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cdbc6",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8966c49",
   "metadata": {},
   "source": [
    "[Tool use](https://docs.anthropic.com/claude/docs/tool-use) lets Claude use external tools. The API uses JSON schema, so we need a way to map Python functions to JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8c948",
   "metadata": {},
   "source": [
    "We'll use [docments](https://fastcore.fast.ai/docments.html) to make defining Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silly_sum(\n",
    "    a:int, # First thing to sum\n",
    "    b:int=1, # Second thing to sum\n",
    "    c:list[int]=None, # A pointless argument\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656740d8",
   "metadata": {},
   "source": [
    "This is what `docments` makes of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a43a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'a': { 'anno': <class 'int'>,\n",
       "         'default': <class 'inspect._empty'>,\n",
       "         'docment': 'First thing to sum'},\n",
       "  'b': {'anno': <class 'int'>, 'default': 1, 'docment': 'Second thing to sum'},\n",
       "  'c': {'anno': list[int], 'default': None, 'docment': 'A pointless argument'},\n",
       "  'return': { 'anno': <class 'int'>,\n",
       "              'default': <class 'inspect._empty'>,\n",
       "              'docment': 'The sum of the inputs'}}\n",
       "```"
      ],
      "text/plain": [
       "{'a': {'docment': 'First thing to sum',\n",
       "  'anno': int,\n",
       "  'default': inspect._empty},\n",
       " 'b': {'docment': 'Second thing to sum', 'anno': int, 'default': 1},\n",
       " 'c': {'docment': 'A pointless argument', 'anno': list[int], 'default': None},\n",
       " 'return': {'docment': 'The sum of the inputs',\n",
       "  'anno': int,\n",
       "  'default': inspect._empty}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = docments(silly_sum, full=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03e76d",
   "metadata": {},
   "source": [
    "Note that this is an [AttrDict](https://fastcore.fast.ai/basics.html#attrdict) so we can treat it like an object, *or* a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd9667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First thing to sum', int)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.a.docment, d['a']['anno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73495a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _types(t:type)->tuple[str,Optional[str]]:\n",
    "    \"Tuple of json schema type name and (if appropriate) array item name\"\n",
    "    tmap = {int:\"integer\", float:\"number\", str:\"string\", bool:\"boolean\", list:\"array\", dict:\"object\"}\n",
    "    if getattr(t, '__origin__', None) in  (list,tuple): return \"array\", tmap.get(t.__args__[0], \"object\")\n",
    "    else: return tmap.get(t, \"object\"), None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50469d6",
   "metadata": {},
   "source": [
    "This internal function is needed to convert Python types into JSON schema types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5096720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('array', 'integer'), ('integer', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_types(list[int]), _types(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e122c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _param(name, info):\n",
    "    \"json schema parameter given `name` and `info` from docments full dict\"\n",
    "    paramt,itemt = _types(info.anno)\n",
    "    pschema = dict(type=paramt, description=info.docment)\n",
    "    if itemt: pschema[\"items\"] = {\"type\": itemt}\n",
    "    if info.default is not empty: pschema[\"default\"] = info.default\n",
    "    return pschema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7bb88",
   "metadata": {},
   "source": [
    "This private function converts a key/value pair from the `docments` structure into the `dict` that will be needed for the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a // {'docment': 'First thing to sum', 'anno': <class 'int'>, 'default': <class 'inspect._empty'>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'integer', 'description': 'First thing to sum'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,o = first(d.items())\n",
    "print(n,'//', o)\n",
    "_param(n, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_schema(f:callable)->dict:\n",
    "    \"Convert function `f` into a JSON schema `dict` for tool use\"\n",
    "    d = docments(f, full=True)\n",
    "    ret = d.pop('return')\n",
    "    paramd = {\n",
    "        'type': \"object\",\n",
    "        'properties': {n:_param(n,o) for n,o in d.items()},\n",
    "        'required': [n for n,o in d.items() if o.default is empty]\n",
    "    }\n",
    "    desc = f.__doc__\n",
    "    if ret.anno is not empty: desc += f'\\n\\nReturns:\\n- type: {_types(ret.anno)[0]}'\n",
    "    if ret.docment: desc += f'\\n- description: {ret.docment}'\n",
    "    return dict(name=f.__name__, description=desc, input_schema=paramd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68039f00",
   "metadata": {},
   "source": [
    "Putting this all together, we can now test getting a schema from `silly_sum`. The tool use spec doesn't support return annotations directly, so we put that in the description instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adds a + b\n",
      "\n",
      "Returns:\n",
      "- type: integer\n",
      "- description: The sum of the inputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'silly_sum',\n",
       " 'input_schema': {'type': 'object',\n",
       "  'properties': {'a': {'type': 'integer', 'description': 'First thing to sum'},\n",
       "   'b': {'type': 'integer',\n",
       "    'description': 'Second thing to sum',\n",
       "    'default': 1},\n",
       "   'c': {'type': 'array',\n",
       "    'description': 'A pointless argument',\n",
       "    'items': {'type': 'integer'},\n",
       "    'default': None}},\n",
       "  'required': ['a']}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_schema(silly_sum)\n",
    "desc = s.pop('description')\n",
    "print(desc)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890a7a3",
   "metadata": {},
   "source": [
    "We'll now get ready to test this out -- first we need a function that Claude can call; we'll write a simple function that adds numbers together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    # First thing to sum\n",
    "    a:int,\n",
    "    # Second thing to sum\n",
    "    b:int=1\n",
    "# The sum of the inputs\n",
    ") -> int:\n",
    "    \"Adds a + b\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "sp = \"You must use the `sums` function instead of adding yourself, but don't mention what tools you use.\"\n",
    "tools=[get_schema(sums)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558deaf4",
   "metadata": {},
   "source": [
    "We'll start a dialog with Claude now. We'll store the messages of our dialog in `msgs`. The first message will be our prompt `pr`, and we'll pass our `tools` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ceeb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "ToolUseBlock(id='toolu_01GZCfB1mAG58UMgv2Vosv9r', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')\n",
       "<details><ul><li>\n",
       "id: msg_01CNbyP4QHZcmrz315nEFHJc</li>\n",
       "<li>content: [{'id': 'toolu_01GZCfB1mAG58UMgv2Vosv9r', 'input': {'a': 604542, 'b': 6458932}, 'name': 'sums', 'type': 'tool_use'}]</li>\n",
       "<li>model: claude-3-haiku-20240307</li>\n",
       "<li>role: assistant</li>\n",
       "<li>stop_reason: tool_use</li>\n",
       "<li>stop_sequence: None</li>\n",
       "<li>type: message</li>\n",
       "<li>usage: {'input_tokens': 414, 'output_tokens': 72}\n",
       "</ul></li></details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01CNbyP4QHZcmrz315nEFHJc', content=[ToolUseBlock(id='toolu_01GZCfB1mAG58UMgv2Vosv9r', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 414; Out: 72; Total: 486)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(pr)\n",
    "r = c(msgs, sp=sp, tools=tools)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d6f16",
   "metadata": {},
   "source": [
    "When Claude decides that it should use a tool, it passes back a `ToolUseBlock` with the name of the tool to call, and the params to use.\n",
    "\n",
    "We need to append the response to the dialog so Claude knows what's happening (since it's stateless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append(mk_msg(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd0116",
   "metadata": {},
   "source": [
    "We don't want to allow it to call just any possible function (that would be a security disaster!) so we create a *namespace* -- that is, a dictionary of allowable function names to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_ns(*funcs:list[callable]) -> dict[str,callable]:\n",
    "    \"Create a `dict` of name to function in `funcs`, to use as a namespace\"\n",
    "    return {f.__name__:f for f in funcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a3ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sums': <function __main__.sums(a: int, b: int = 1) -> int>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = mk_ns(sums)\n",
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def call_func(tr, ns=None):\n",
    "    \"Call the function in the tool response `tr`, using namespace `ns`\"\n",
    "    if ns is None: ns=globals()\n",
    "    if not isinstance(ns, abc.Mapping): ns = mk_ns(*ns)\n",
    "    fc = find_block(r, tool_use_block.ToolUseBlock)\n",
    "    return ns[fc.name](**fc.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b2ed0",
   "metadata": {},
   "source": [
    "We can now use the function requested by Claude. We look it up in `ns`, and pass in the provided parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f81ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7063474"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = call_func(r, ns=ns)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_toolres(r, res=None, ns=None):\n",
    "    \"Create a `tool_result` message from response `r`\"\n",
    "    if not hasattr(r, 'content'): return r\n",
    "    tool = first(o for o in r.content if isinstance(o,tool_use_block.ToolUseBlock))\n",
    "    if not tool: return r\n",
    "    if res is None: res = call_func(r, ns)\n",
    "    tr = dict(type=\"tool_result\", tool_use_id=tool.id, content=str(res))\n",
    "    return mk_msg([tr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634b3bf",
   "metadata": {},
   "source": [
    "In order to tell Claude the result of the tool call, we pass back a `tool_result` message, created by calling `call_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'tool_result',\n",
       "   'tool_use_id': 'toolu_01GZCfB1mAG58UMgv2Vosv9r',\n",
       "   'content': '7063474'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = mk_toolres(r, res=res, ns=ns)\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d16be5",
   "metadata": {},
   "source": [
    "We add this to our dialog, and now Claude has all the information it needs to answer our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed99502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sum of 604542 and 6458932 is 7063474.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs.append(tr)\n",
    "contents(c(msgs, sp=sp, tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e37733",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0da2d",
   "metadata": {},
   "source": [
    "Rather than manually adding the responses to a dialog, we'll create a simple `Chat` class to do that for us, each time we make a request. We'll also store the system prompt and tools here, to avoid passing them every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c10e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Chat:\n",
    "    def __init__(self, model=None, cli=None, sp='', tools=None):\n",
    "        \"Anthropic chat client\"\n",
    "        assert model or cli\n",
    "        self.c = (cli or Client(model))\n",
    "        self.h,self.sp,self.tools = [],sp,tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6319279",
   "metadata": {},
   "source": [
    "The class stores the `Client` that will provide the responses in `c`, and a history of messages in `h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab5563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Total: 0, [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"If asked to add things up, use the `sums` function instead of doing it yourself. Never mention what tools you use.\"\n",
    "chat = Chat(model, sp=sp, tools=[sums])\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self:Chat, pr, temp=0, maxtok=4096, stop=None, ns=None, **kw):\n",
    "    if ns is None: ns=self.tools\n",
    "    self.h = mk_msgs(self.h + [mk_toolres(pr, ns=ns)])\n",
    "    if self.tools: kw['tools'] = [get_schema(o) for o in self.tools]\n",
    "    res = self.c(self.h, sp=self.sp, temp=temp, maxtok=maxtok, stop=stop, **kw)\n",
    "    self.h.append(mk_msg(res, role='assistant'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ecd7f",
   "metadata": {},
   "source": [
    "The `__call__` method just passes the request along to the `Client`, but rather than just passing in this one prompt, it appends it to the history and passes it all along. As a result, we now have state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Jeremy, as you told me earlier.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I'm Jeremy\")\n",
    "contents(chat(\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041a7c",
   "metadata": {},
   "source": [
    "We automagically get streamlined tool use as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc8c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is 604542+6458932?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d28a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Okay, let me calculate that for you:\n",
       "<details><ul><li>\n",
       "id: msg_01BuonV8LEsPgVGxQcnKtwek</li>\n",
       "<li>content: [{'text': 'Okay, let me calculate that for you:', 'type': 'text'}, {'id': 'toolu_018q7WHBsxxyzLWPmR9THBHN', 'input': {'a': 604542, 'b': 6458932}, 'name': 'sums', 'type': 'tool_use'}]</li>\n",
       "<li>model: claude-3-haiku-20240307</li>\n",
       "<li>role: assistant</li>\n",
       "<li>stop_reason: tool_use</li>\n",
       "<li>stop_sequence: None</li>\n",
       "<li>type: message</li>\n",
       "<li>usage: {'input_tokens': 493, 'output_tokens': 83}\n",
       "</ul></li></details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01BuonV8LEsPgVGxQcnKtwek', content=[TextBlock(text='Okay, let me calculate that for you:', type='text'), ToolUseBlock(id='toolu_018q7WHBsxxyzLWPmR9THBHN', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 493; Out: 83; Total: 576)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a3e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The sum of 604,542 and 6,458,932 is 7,063,474.\n",
       "<details><ul><li>\n",
       "id: msg_013dUcWHJhbDVRThcFomcjsa</li>\n",
       "<li>content: [{'text': 'The sum of 604,542 and 6,458,932 is 7,063,474.', 'type': 'text'}]</li>\n",
       "<li>model: claude-3-haiku-20240307</li>\n",
       "<li>role: assistant</li>\n",
       "<li>stop_reason: end_turn</li>\n",
       "<li>stop_sequence: None</li>\n",
       "<li>type: message</li>\n",
       "<li>usage: {'input_tokens': 590, 'output_tokens': 28}\n",
       "</ul></li></details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_013dUcWHJhbDVRThcFomcjsa', content=[TextBlock(text='The sum of 604,542 and 6,458,932 is 7,063,474.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 590; Out: 28; Total: 618)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2979db8",
   "metadata": {},
   "source": [
    "It should be correct, because it actually used our Python function to do the addition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91127d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7063474"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39be44",
   "metadata": {},
   "source": [
    "## XML helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08eb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def hl_md(s, lang='xml'):\n",
    "    \"Syntax highlight `s` using `lang`\"\n",
    "    if Markdown: return Markdown(f'```{lang}\\n{s}\\n```')\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def to_xml(node, hl=False):\n",
    "    \"Convert `node` to an XML string\"\n",
    "    def mk_el(tag, cs, attrs):\n",
    "        el = ET.Element(tag, attrib=attrs)\n",
    "        if isinstance(cs, list): el.extend([mk_el(*o) for o in cs])\n",
    "        elif cs is not None: el.text = str(cs)\n",
    "        return el\n",
    "\n",
    "    root = mk_el(*node)\n",
    "    ET.indent(root)\n",
    "    res = ET.tostring(root, encoding='unicode')\n",
    "    return hl_md(res) if hl else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def xt(tag, c=None, **kw):\n",
    "    \"Helper to create appropriate data structure for `to_xml`\"\n",
    "    kw = {k.lstrip('_'):str(v) for k,v in kw.items()}\n",
    "    return tag,c,kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd36f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "g = globals()\n",
    "tags = 'div','img','h1','h2','h3','h4','h5','p','hr','span','html'\n",
    "for o in tags: g[o] = partial(xt, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = html([\n",
    "    p('This is a paragraph'),\n",
    "    hr(),\n",
    "    xt('x-custom', foo='bar'),\n",
    "    img(src='http://example.prg'),\n",
    "    div([\n",
    "        h1('This is a header'),\n",
    "        h2('This is a sub-header', style='k:v'),\n",
    "    ], _class='foo')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25692697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```xml\n",
       "<html>\n",
       "  <p>This is a paragraph</p>\n",
       "  <hr />\n",
       "  <x-custom foo=\"bar\" />\n",
       "  <img src=\"http://example.prg\" />\n",
       "  <div class=\"foo\">\n",
       "    <h1>This is a header</h1>\n",
       "    <h2 style=\"k:v\">This is a sub-header</h2>\n",
       "  </div>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_xml(a, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf251158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def json_to_xml(d:dict, rnm:str)->str:\n",
    "    \"Convert `d` to XML with root name `rnm`\"\n",
    "    root = ET.Element(rnm)\n",
    "    def build_xml(data, parent):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))\n",
    "        elif isinstance(data, list):\n",
    "            for item in data: build_xml(item, ET.SubElement(parent, 'item'))\n",
    "        else: parent.text = str(data)\n",
    "    build_xml(d, root)\n",
    "    ET.indent(root)\n",
    "    return ET.tostring(root, encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<person>\n",
      "  <surname>Howard</surname>\n",
      "  <firstnames>\n",
      "    <item>Jeremy</item>\n",
      "    <item>Peter</item>\n",
      "  </firstnames>\n",
      "  <address>\n",
      "    <state>Queensland</state>\n",
      "    <country>Australia</country>\n",
      "  </address>\n",
      "</person>\n"
     ]
    }
   ],
   "source": [
    "a = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n",
    "         address=dict(state='Queensland',country='Australia'))\n",
    "print(json_to_xml(a, 'person'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcf4e1",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a02334",
   "metadata": {},
   "source": [
    "Not done yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
