{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Claudio's source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b5d38",
   "metadata": {},
   "source": [
    "This is the 'literate' source code for Claudio. You can view the fully rendered version of the notebook [here](https://answerdotai.github.io/claudio/core.html), or you can clone the git repo and run the [interactive notebook](https://github.com/AnswerDotAI/claudio/blob/main/00_core.ipynb) in Jupyter. The notebook is converted the [Python module claudio/core.py](https://github.com/AnswerDotAI/claudio/blob/main/claudio/core.py) using [nbdev](https://nbdev.fast.ai/). The goal of this source code is to both create the Python module, and also to teach the reader *how* it is created, without assuming much existing knowledge about Claude's API.\n",
    "\n",
    "Most of the time you'll see that we write some source code *first*, and then a description or discussion of it *afterwards*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad998e-4bb1-4bed-abf4-6e8606cb2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['ANTHROPIC_LOG'] = 'debug'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16f396",
   "metadata": {},
   "source": [
    "To print every HTTP request and response in full, uncomment the above line. This functionality is provided by Anthropic's SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tokenize, ast, inspect, inspect, typing\n",
    "import xml.etree.ElementTree as ET, json\n",
    "from collections import abc\n",
    "\n",
    "from anthropic import Anthropic\n",
    "from anthropic.types import Usage, TextBlock, Message\n",
    "from anthropic.types.beta.tools import ToolsBetaMessage, tool_use_block\n",
    "from inspect import Parameter\n",
    "from io import BytesIO\n",
    "try: from IPython import display\n",
    "except: display=None\n",
    "\n",
    "from fastcore.docments import docments\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d0ec8",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "Note the \"Exported source\" collapsible widget below. That shows that this piece of code will be exported into the python module that this notebook creates. No other code will be included -- any other code in this notebook is just for demonstration, documentation, and testing.\n",
    "\n",
    "You can toggle expanding/collapsing the source code of all exported sections by using the `</> Code` menu in the top right of the rendered notebook page.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "models = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdeca1e",
   "metadata": {},
   "source": [
    "These are the current versions of Anthropic's model at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "empty = Parameter.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71985a9c",
   "metadata": {},
   "source": [
    "For examples, we'll use Haiku, since it's fast and cheap (and surprisingly good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## Antropic SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b53a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23055b40",
   "metadata": {},
   "source": [
    "This is what Anthropic's SDK provides for interacting with Python. To use it, pass it a list of *messages*, with *content* and a *role*. The roles should alternate between *user* and *assistant*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28b175",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "After the code below you'll see an indented section with an orange vertical line on the left. This is used to show the *result* of running the code above. Because the code is running in a Jupyter Notebook, we don't have to use `print` to display results, we can just type the expression directly, as we do with `r` here.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec40731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01GqMVsZxfNekkAGksqyC1To', content=[TextBlock(text=\"It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=10, output_tokens=57))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebf6d8",
   "metadata": {},
   "source": [
    "### Formatting output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c40a9",
   "metadata": {},
   "source": [
    "That output is pretty long and hard to read, so let's clean it up. We'll start by pulling out the `Content` part of the message.\n",
    "To do that, we're going to write our first function which will be included to the `claudia/core.py` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c70683",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "In the rendered version of the notebook, for each exported function you'll see 3 things, in this order:\n",
    "\n",
    "- The source code (in a collapsible \"Exported source\" block)\n",
    "- The signature (with the symbol name as a heading, with a horizontal rule above)\n",
    "- The doc string (in italics).\n",
    "\n",
    "After that, we generally provide a bit more detail on what we've created, and why, along with a sample usage.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_block(r, blk_type=TextBlock):\n",
    "    \"Find the first block of type `blk_type` in `r.content`.\"\n",
    "    return first(o for o in r.content if isinstance(o,blk_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c9d29",
   "metadata": {},
   "source": [
    "This makes it easier to grab the needed parts of Claude's responses, which can include multiple pieces of content. By default, we look for the first text block. That will generally have the content we want to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692e934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlock(text=\"It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\", type='text')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_block(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def contents(r):\n",
    "    \"Helper to get the contents from Claude response `r`.\"\n",
    "    blk = find_block(r)\n",
    "    if not blk: blk = r.content[0]\n",
    "    return blk.text.strip() if hasattr(blk,'text') else blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ace55a",
   "metadata": {},
   "source": [
    "For display purposes, we often just want to show the text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b8704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def _repr_markdown_(self:(ToolsBetaMessage,Message)):\n",
    "    det = '\\n- '.join(f'{k}: {v}' for k,v in self.dict().items())\n",
    "    return f\"\"\"{contents(self)}\n",
    "\n",
    "<details>\n",
    "\n",
    "{det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10da614",
   "metadata": {},
   "source": [
    "Jupyter looks for a `_repr_markdown_` method in displayed objects; we add this in order to display just the content text, and collapse full details into a hideable section. Note that `patch` is from `fastcore`, and is used to add (or replace) functionality in an existing class. We pass the class(es) that we want to patch as type annotations to `self`. In this case, `_repr_markdown_` is being added to Anthropic's `ToolsBetaMessage` and `Message` classes, so when we display the message now we just see the contents, and the details are hidden away in a collapsible details block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01GqMVsZxfNekkAGksqyC1To\n",
       "- content: [{'text': \"It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\", 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 10, 'output_tokens': 57}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01GqMVsZxfNekkAGksqyC1To', content=[TextBlock(text=\"It's nice to meet you, Jeremy! As an AI assistant, I don't have a personal identity, but I'm happy to chat with you and try my best to assist you with any questions or tasks you may have. Please feel free to ask me anything.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=10, output_tokens=57))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3488b",
   "metadata": {},
   "source": [
    "One key part of the response is the `usage` key, which tells us how many tokens we used by returning a `Usage` object.\n",
    "\n",
    "We'll add some helpers to make things a bit cleaner for creating and formatting these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eb735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=10, output_tokens=57)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, out=0):\n",
    "    \"Slightly more concise version of `Usage`.\"\n",
    "    return Usage(input_tokens=inp, output_tokens=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14040037",
   "metadata": {},
   "source": [
    "The constructor provided by Anthropic is rather verbose, so we clean it up a bit, using a lowercase version of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b94be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=5, output_tokens=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch(as_prop=True)\n",
    "def total(self:Usage): return self.input_tokens+self.output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c38b5",
   "metadata": {},
   "source": [
    "Adding a `total` property to `Usage` makes it easier to see how many tokens we've used up altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf68b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5,1).total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:Usage): return f'In: {self.input_tokens}; Out: {self.output_tokens}; Total: {self.total}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262cbb2",
   "metadata": {},
   "source": [
    "In python, patching `__repr__` let's us change how an object is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 10; Out: 57; Total: 67"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:Usage, b):\n",
    "    return usage(self.input_tokens+b.input_tokens, self.output_tokens+b.output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420dbdd",
   "metadata": {},
   "source": [
    "And, patching `__add__` let's make `+` work on a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ed18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 20; Out: 114; Total: 134"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage+r.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef435b67",
   "metadata": {},
   "source": [
    "### Creating messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb52ff",
   "metadata": {},
   "source": [
    "Creating correctly formatted `dict`s from scratch every time isn't very handy, so next up we'll add helpers for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_msg(content, role='user', **kw):\n",
    "    return dict(role=role, content=content, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76545a",
   "metadata": {},
   "source": [
    "We make things a bit more convenient by writing a function to create a message for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3d284",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "You may have noticed that we didn't export the `mk_msg` function (i.e. there's no \"Exported source\" block around it). That's because we'll need more functionality in our final version than this version has -- so we'll be defining a more complete version later. Rather than refactoring/editing in notebooks, often it's helpful to simply gradually build up complexity by re-defining a symbol.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28542783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': \"I'm Jeremy\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'm Jeremy\"\n",
    "m = mk_msg(prompt)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba165ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It's nice to meet you, Jeremy! How can I assist you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01WDH5Hegmij4xEwH9ispkrW\n",
       "- content: [{'text': \"It's nice to meet you, Jeremy! How can I assist you today?\", 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 10, 'output_tokens': 19}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01WDH5Hegmij4xEwH9ispkrW', content=[TextBlock(text=\"It's nice to meet you, Jeremy! How can I assist you today?\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 10; Out: 19; Total: 29)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.messages.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_msgs(msgs, **kw):\n",
    "    \"Helper to set 'assistant' role on alternate messages.\"\n",
    "    if isinstance(msgs,str): msgs=[msgs]\n",
    "    return [mk_msg(o, ('user','assistant')[i%2], **kw) for i,o in enumerate(msgs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b5739",
   "metadata": {},
   "source": [
    "LLMs, including Claude, don't actually have state, but instead dialogs are created by passing back all previous prompts and responses every time. With Claude, they always alternate *user* and *assistant*. Therefore we create a function to make it easier to build up these dialog lists.\n",
    "\n",
    "But to do so, we need to update `mk_msg` so that we can't only pass a `str` as `content`, but can also pass a `dict` or an object with a `content` attr, since these are both types of message that Claude can create. To do so, we check for a `content` key or attr, and use it if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_msg(content, role='user', **kw):\n",
    "    \"Helper to create a `dict` appropriate for a Claude message.\"\n",
    "    if hasattr(content, 'content'): content,role = content.content,content.role\n",
    "    if isinstance(content, abc.Mapping): content=content['content']\n",
    "    return dict(role=role, content=content, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58b15f",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "As mentioned above, we've now re-defined `mk_msg`, and this version is the one we export to the Python module.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Jeremy\"},\n",
       " {'role': 'assistant',\n",
       "  'content': [TextBlock(text=\"It's nice to meet you, Jeremy! How can I assist you today?\", type='text')]},\n",
       " {'role': 'user', 'content': 'I forgot my name. Can you remind me please?'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs([prompt, r, 'I forgot my name. Can you remind me please?'])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf95e1",
   "metadata": {},
   "source": [
    "Now, if we pass this list of messages to Claude, the model treats it as a conversation to respond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c464f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm afraid I don't actually know your name. You introduced yourself as Jeremy, but if you've forgotten your name, I don't have any other information about what your name is. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have access to your personal information or identity details. If you've genuinely forgotten your name, I would suggest trying to recall it or contacting someone who knows you well to help remind you.\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01RoqBDVrbD8cwuDYGCEh86F\n",
       "- content: [{'text': \"I'm afraid I don't actually know your name. You introduced yourself as Jeremy, but if you've forgotten your name, I don't have any other information about what your name is. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have access to your personal information or identity details. If you've genuinely forgotten your name, I would suggest trying to recall it or contacting someone who knows you well to help remind you.\", 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 43, 'output_tokens': 103}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01RoqBDVrbD8cwuDYGCEh86F', content=[TextBlock(text=\"I'm afraid I don't actually know your name. You introduced yourself as Jeremy, but if you've forgotten your name, I don't have any other information about what your name is. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have access to your personal information or identity details. If you've genuinely forgotten your name, I would suggest trying to recall it or contacting someone who knows you well to help remind you.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 43; Out: 103; Total: 146)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.messages.create(messages=msgs, model=model, max_tokens=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f8a4d",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None):\n",
    "        \"Basic Anthropic messages client.\"\n",
    "        self.model,self.use = model,Usage(input_tokens=0,output_tokens=0)\n",
    "        self.c = (cli or Anthropic())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e39f0",
   "metadata": {},
   "source": [
    "We'll create a simple `Client` for `Anthropic` which tracks usage stores the model to use. We don't add any methods right away -- instead we'll use `patch` for that so we can add and document them incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(model)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r:ToolsBetaMessage):\n",
    "    \"Store the result of the message and accrue total usage.\"\n",
    "    self.result = r\n",
    "    self.use += r.usage\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2eb9b",
   "metadata": {},
   "source": [
    "We use a `_` prefix on private methods, but we document them here in the interests of literate source code.\n",
    "\n",
    "`_r` will be used each time we get a new result, to track usage and also to keep the result available for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 10; Out: 19; Total: 29"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb96c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __call__(self:Client, msgs, sp='', temp=0, maxtok=4096, stop=None, **kw):\n",
    "    \"Make a call to Claude without streaming.\"\n",
    "    r = self.c.beta.tools.messages.create(\n",
    "        model=self.model, messages=mk_msgs(msgs), max_tokens=maxtok, system=sp, temperature=temp, stop_sequences=stop, **kw)\n",
    "    return self._r(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee10c8",
   "metadata": {},
   "source": [
    "Defining `__call__` let's us use an object like a function (i.e it's *callable*). We use it as a small wrapper over `messages.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a38e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01TgP2TdWGP68VfHmmrQuSqF\n",
       "- content: [{'text': 'Hello! How can I assist you today?', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 8, 'output_tokens': 12}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01TgP2TdWGP68VfHmmrQuSqF', content=[TextBlock(text='Hello! How can I assist you today?', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 8; Out: 12; Total: 20)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3a5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 18; Out: 31; Total: 49"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def stream(self:Client, msgs, sp='', temp=0, maxtok=4096, stop=None, **kw):\n",
    "    \"Make a call to Claude, streaming the result.\"\n",
    "    with self.c.messages.stream(model=self.model, messages=mk_msgs(msgs), max_tokens=maxtok,\n",
    "                                system=sp, temperature=temp, stop_sequences=stop, **kw) as s:\n",
    "        yield from s.text_stream\n",
    "        return self._r(s.get_final_message())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf74ead",
   "metadata": {},
   "source": [
    "We also define a wrapper over `messages.stream`, which is like `messages.create`, but streams the response back incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "for o in c.stream('Hi'): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb25f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 26; Out: 43; Total: 69"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cdbc6",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec35c95",
   "metadata": {},
   "source": [
    "[Tool use](https://docs.anthropic.com/claude/docs/tool-use) lets Claude use external tools. The API uses JSON schema, so we need a way to map Python functions to JSON.\n",
    "\n",
    "We'll use [docments](https://fastcore.fast.ai/docments.html) to make defining Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a017af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silly_sum(\n",
    "    a:int, # First thing to sum\n",
    "    b:int=1, # Second thing to sum\n",
    "    c:list[int]=None, # A pointless argument\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ff443",
   "metadata": {},
   "source": [
    "This is what `docments` makes of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'a': { 'anno': <class 'int'>,\n",
       "         'default': <class 'inspect._empty'>,\n",
       "         'docment': 'First thing to sum'},\n",
       "  'b': {'anno': <class 'int'>, 'default': 1, 'docment': 'Second thing to sum'},\n",
       "  'c': {'anno': list[int], 'default': None, 'docment': 'A pointless argument'},\n",
       "  'return': { 'anno': <class 'int'>,\n",
       "              'default': <class 'inspect._empty'>,\n",
       "              'docment': 'The sum of the inputs'}}\n",
       "```"
      ],
      "text/plain": [
       "{'a': {'docment': 'First thing to sum',\n",
       "  'anno': int,\n",
       "  'default': inspect._empty},\n",
       " 'b': {'docment': 'Second thing to sum', 'anno': int, 'default': 1},\n",
       " 'c': {'docment': 'A pointless argument', 'anno': list[int], 'default': None},\n",
       " 'return': {'docment': 'The sum of the inputs',\n",
       "  'anno': int,\n",
       "  'default': inspect._empty}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = docments(silly_sum, full=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e44ea",
   "metadata": {},
   "source": [
    "Note that this is an [AttrDict](https://fastcore.fast.ai/basics.html#attrdict) so we can treat it like an object, *or* a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First thing to sum', int)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.a.docment, d['a']['anno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _types(t:type)->tuple[str,Optional[str]]:\n",
    "    \"Tuple of json schema type name and (if appropriate) array item name.\"\n",
    "    tmap = {int:\"integer\", float:\"number\", str:\"string\", bool:\"boolean\", list:\"array\", dict:\"object\"}\n",
    "    if getattr(t, '__origin__', None) in  (list,tuple): return \"array\", tmap.get(t.__args__[0], \"object\")\n",
    "    else: return tmap.get(t, \"object\"), None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf73046",
   "metadata": {},
   "source": [
    "This internal function is needed to convert Python types into JSON schema types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('array', 'integer'), ('integer', None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_types(list[int]), _types(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _param(name, info):\n",
    "    \"json schema parameter given `name` and `info` from docments full dict.\"\n",
    "    paramt,itemt = _types(info.anno)\n",
    "    pschema = dict(type=paramt, description=info.docment)\n",
    "    if itemt: pschema[\"items\"] = {\"type\": itemt}\n",
    "    if info.default is not empty: pschema[\"default\"] = info.default\n",
    "    return pschema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337d6bd",
   "metadata": {},
   "source": [
    "This private function converts a key/value pair from the `docments` structure into the `dict` that will be needed for the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a // {'docment': 'First thing to sum', 'anno': <class 'int'>, 'default': <class 'inspect._empty'>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'integer', 'description': 'First thing to sum'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,o = first(d.items())\n",
    "print(n,'//', o)\n",
    "_param(n, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_schema(f:callable)->dict:\n",
    "    \"Convert function `f` into a JSON schema `dict` for tool use.\"\n",
    "    d = docments(f, full=True)\n",
    "    ret = d.pop('return')\n",
    "    paramd = {\n",
    "        'type': \"object\",\n",
    "        'properties': {n:_param(n,o) for n,o in d.items()},\n",
    "        'required': [n for n,o in d.items() if o.default is empty]\n",
    "    }\n",
    "    desc = f.__doc__\n",
    "    if ret.anno is not empty: desc += f'\\n\\nReturns:\\n- type: {_types(ret.anno)[0]}'\n",
    "    if ret.docment: desc += f'\\n- description: {ret.docment}'\n",
    "    return dict(name=f.__name__, description=desc, input_schema=paramd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59df671",
   "metadata": {},
   "source": [
    "Putting this all together, we can now test getting a schema from `silly_sum`. The tool use spec doesn't support return annotations directly, so we put that in the description instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adds a + b.\n",
      "\n",
      "Returns:\n",
      "- type: integer\n",
      "- description: The sum of the inputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'silly_sum',\n",
       " 'input_schema': {'type': 'object',\n",
       "  'properties': {'a': {'type': 'integer', 'description': 'First thing to sum'},\n",
       "   'b': {'type': 'integer',\n",
       "    'description': 'Second thing to sum',\n",
       "    'default': 1},\n",
       "   'c': {'type': 'array',\n",
       "    'description': 'A pointless argument',\n",
       "    'items': {'type': 'integer'},\n",
       "    'default': None}},\n",
       "  'required': ['a']}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_schema(silly_sum)\n",
    "desc = s.pop('description')\n",
    "print(desc)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522dc97",
   "metadata": {},
   "source": [
    "We'll now get ready to test this out -- first we need a function that Claude can call; we'll write a simple function that adds numbers together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    # First thing to sum\n",
    "    a:int,\n",
    "    # Second thing to sum\n",
    "    b:int=1\n",
    "# The sum of the inputs\n",
    ") -> int:\n",
    "    \"Adds a + b.\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff81d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "sp = \"You must use the `sums` function instead of adding yourself, but don't mention what tools you use.\"\n",
    "tools=[get_schema(sums)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91937f47",
   "metadata": {},
   "source": [
    "We'll start a dialog with Claude now. We'll store the messages of our dialog in `msgs`. The first message will be our prompt `pr`, and we'll pass our `tools` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ceeb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ToolUseBlock(id='toolu_0193iWxNNL9hMQLefhW8x4xo', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01XBsa5kDACbbb66SUDNstFJ\n",
       "- content: [{'id': 'toolu_0193iWxNNL9hMQLefhW8x4xo', 'input': {'a': 604542, 'b': 6458932}, 'name': 'sums', 'type': 'tool_use'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: tool_use\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 414, 'output_tokens': 72}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01XBsa5kDACbbb66SUDNstFJ', content=[ToolUseBlock(id='toolu_0193iWxNNL9hMQLefhW8x4xo', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 414; Out: 72; Total: 486)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(pr)\n",
    "r = c(msgs, sp=sp, tools=tools)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2fce0",
   "metadata": {},
   "source": [
    "When Claude decides that it should use a tool, it passes back a `ToolUseBlock` with the name of the tool to call, and the params to use.\n",
    "\n",
    "We need to append the response to the dialog so Claude knows what's happening (since it's stateless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append(mk_msg(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815eaff3",
   "metadata": {},
   "source": [
    "We don't want to allow it to call just any possible function (that would be a security disaster!) so we create a *namespace* -- that is, a dictionary of allowable function names to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_ns(*funcs:list[callable]) -> dict[str,callable]:\n",
    "    \"Create a `dict` of name to function in `funcs`, to use as a namespace\"\n",
    "    return {f.__name__:f for f in funcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sums': <function __main__.sums(a: int, b: int = 1) -> int>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = mk_ns(sums)\n",
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def call_func(tr, ns=None):\n",
    "    \"Call the function in the tool response `tr`, using namespace `ns`.\"\n",
    "    if ns is None: ns=globals()\n",
    "    if not isinstance(ns, abc.Mapping): ns = mk_ns(*ns)\n",
    "    fc = find_block(r, tool_use_block.ToolUseBlock)\n",
    "    return ns[fc.name](**fc.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f23eb",
   "metadata": {},
   "source": [
    "We can now use the function requested by Claude. We look it up in `ns`, and pass in the provided parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f81ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7063474"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = call_func(r, ns=ns)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_toolres(r, res=None, ns=None):\n",
    "    \"Create a `tool_result` message from response `r`.\"\n",
    "    if not hasattr(r, 'content'): return r\n",
    "    tool = first(o for o in r.content if isinstance(o,tool_use_block.ToolUseBlock))\n",
    "    if not tool: return r\n",
    "    if res is None: res = call_func(r, ns)\n",
    "    tr = dict(type=\"tool_result\", tool_use_id=tool.id, content=str(res))\n",
    "    return mk_msg([tr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57d1ca",
   "metadata": {},
   "source": [
    "In order to tell Claude the result of the tool call, we pass back a `tool_result` message, created by calling `call_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13de1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'tool_result',\n",
       "   'tool_use_id': 'toolu_0193iWxNNL9hMQLefhW8x4xo',\n",
       "   'content': '7063474'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = mk_toolres(r, res=res, ns=ns)\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4fe37",
   "metadata": {},
   "source": [
    "We add this to our dialog, and now Claude has all the information it needs to answer our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed99502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sum of 604542 and 6458932 is 7063474.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs.append(tr)\n",
    "contents(c(msgs, sp=sp, tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea144b8",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419fab81",
   "metadata": {},
   "source": [
    "Rather than manually adding the responses to a dialog, we'll create a simple `Chat` class to do that for us, each time we make a request. We'll also store the system prompt and tools here, to avoid passing them every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Chat:\n",
    "    def __init__(self, model=None, cli=None, sp='', tools=None):\n",
    "        \"Anthropic chat client.\"\n",
    "        assert model or cli\n",
    "        self.c = (cli or Client(model))\n",
    "        self.h,self.sp,self.tools = [],sp,tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f16d4e",
   "metadata": {},
   "source": [
    "The class stores the `Client` that will provide the responses in `c`, and a history of messages in `h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b837c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Total: 0, [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"If asked to add things up, use the `sums` function instead of doing it yourself. Never mention what tools you use.\"\n",
    "chat = Chat(model, sp=sp)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aad233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _add_prefill(prefill, r):\n",
    "    \"Add `prefill` to the start of response `r`, since Claude doesn't include it otherwise\"\n",
    "    if not prefill: return\n",
    "    blk = find_block(r)\n",
    "    blk.text = prefill + blk.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a25253",
   "metadata": {},
   "source": [
    "Claude supports adding an extra `assistant` message at the end, which contains the *prefill* -- i.e. the text we want Claude to assume the response starts with. However Claude doesn't actually repeat that in the response, so for convenience we'll add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __call__(self:Chat, pr, temp=0, maxtok=4096, stop=None, ns=None, prefill='', **kw):\n",
    "    if ns is None: ns=self.tools\n",
    "    if isinstance(pr,str): pr = pr.strip()\n",
    "    self.h.append(mk_toolres(pr, ns=ns))\n",
    "    if self.tools: kw['tools'] = [get_schema(o) for o in self.tools]\n",
    "    res = self.c(self.h + ([prefill.strip()] if prefill else []), sp=self.sp, temp=temp, maxtok=maxtok, stop=stop, **kw)\n",
    "    _add_prefill(prefill, res)\n",
    "    self.h.append(mk_msg(res, role='assistant'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c5cd7",
   "metadata": {},
   "source": [
    "The `__call__` method just passes the request along to the `Client`, but rather than just passing in this one prompt, it appends it to the history and passes it all along. As a result, we now have state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40073f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Jeremy.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I'm Jeremy\")\n",
    "contents(chat(\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd0186",
   "metadata": {},
   "source": [
    "Let's try out prefill too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Concisely, what is the meaning of life?\"\n",
    "pref = 'According to Douglas Adams,'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6b93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to Douglas Adams,  the answer is 42.\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01VkMDbaEybi1Xz52Rsoz3Jr\n",
       "- content: [{'text': 'According to Douglas Adams,  the answer is 42.', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 124, 'output_tokens': 10}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01VkMDbaEybi1Xz52Rsoz3Jr', content=[TextBlock(text='According to Douglas Adams,  the answer is 42.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 124; Out: 10; Total: 134)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(q, prefill=pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee372cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def stream(self:Chat, pr, temp=0, maxtok=4096, stop=None, prefill='', **kw):\n",
    "    \"Add a prompt and get a response from the chat dialog, streaming the result\"\n",
    "    if isinstance(pr,str): pr = pr.strip()\n",
    "    self.h.append(pr)\n",
    "    if prefill: yield(prefill)\n",
    "    yield from self.c.stream(self.h + ([prefill.strip()] if prefill else []), sp=self.sp, temp=temp, maxtok=maxtok, stop=stop, **kw)\n",
    "    _add_prefill(prefill, self.c.result)\n",
    "    self.h.append(mk_msg(self.c.result, role='assistant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aee23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's nice to meet you, Jeremy! I'm an AI assistant created by Anthropic. I'm here to help with any tasks or questions you may have. Please let me know if there's anything I can assist you with."
     ]
    }
   ],
   "source": [
    "chat = Chat(model, sp=sp)\n",
    "for o in chat.stream(\"I'm Jeremy\"): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa466638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Douglas Adams,  the answer is 42."
     ]
    }
   ],
   "source": [
    "for o in chat.stream(q, prefill=pref): print(o, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac28cde",
   "metadata": {},
   "source": [
    "### Chat tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f7edf",
   "metadata": {},
   "source": [
    "We automagically get streamlined tool use as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6535cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is 604542+6458932?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797741c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ToolUseBlock(id='toolu_01Kg1appFFPkxHMvUXewgBky', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01Uv8ujpvg7wYsoSvc9hBoTd\n",
       "- content: [{'id': 'toolu_01Kg1appFFPkxHMvUXewgBky', 'input': {'a': 604542, 'b': 6458932}, 'name': 'sums', 'type': 'tool_use'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: tool_use\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 418, 'output_tokens': 72}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01Uv8ujpvg7wYsoSvc9hBoTd', content=[ToolUseBlock(id='toolu_01Kg1appFFPkxHMvUXewgBky', input={'a': 604542, 'b': 6458932}, name='sums', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=In: 418; Out: 72; Total: 490)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=sp, tools=[sums])\n",
    "r = chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sum of 604542 and 6458932 is 7063474.\n",
       "\n",
       "<details>\n",
       "\n",
       "id: msg_01AfTpTHU3evB2BW1JH9ufF1\n",
       "- content: [{'text': 'The sum of 604542 and 6458932 is 7063474.', 'type': 'text'}]\n",
       "- model: claude-3-haiku-20240307\n",
       "- role: assistant\n",
       "- stop_reason: end_turn\n",
       "- stop_sequence: None\n",
       "- type: message\n",
       "- usage: {'input_tokens': 505, 'output_tokens': 23}\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ToolsBetaMessage(id='msg_01AfTpTHU3evB2BW1JH9ufF1', content=[TextBlock(text='The sum of 604542 and 6458932 is 7063474.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 505; Out: 23; Total: 528)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7054a02",
   "metadata": {},
   "source": [
    "It should be correct, because it actually used our Python function to do the addition. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff0879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7063474"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1dd4c3",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdb122",
   "metadata": {},
   "source": [
    "Not done yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68932d15",
   "metadata": {},
   "source": [
    "## XML helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489fb45",
   "metadata": {},
   "source": [
    "TODO: Document this bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def hl_md(s, lang='xml'):\n",
    "    \"Syntax highlight `s` using `lang`.\"\n",
    "    if display: return display.Markdown(f'```{lang}\\n{s}\\n```')\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce74be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def to_xml(node, hl=False):\n",
    "    \"Convert `node` to an XML string.\"\n",
    "    def mk_el(tag, cs, attrs):\n",
    "        el = ET.Element(tag, attrib=attrs)\n",
    "        if isinstance(cs, list): el.extend([mk_el(*o) for o in cs])\n",
    "        elif cs is not None: el.text = str(cs)\n",
    "        return el\n",
    "\n",
    "    root = mk_el(*node)\n",
    "    ET.indent(root)\n",
    "    res = ET.tostring(root, encoding='unicode')\n",
    "    return hl_md(res) if hl else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def xt(tag, c=None, **kw):\n",
    "    \"Helper to create appropriate data structure for `to_xml`.\"\n",
    "    kw = {k.lstrip('_'):str(v) for k,v in kw.items()}\n",
    "    return tag,c,kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d533e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "g = globals()\n",
    "tags = 'div','img','h1','h2','h3','h4','h5','p','hr','span','html'\n",
    "for o in tags: g[o] = partial(xt, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2664cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = html([\n",
    "    p('This is a paragraph'),\n",
    "    hr(),\n",
    "    xt('x-custom', foo='bar'),\n",
    "    img(src='http://example.prg'),\n",
    "    div([\n",
    "        h1('This is a header'),\n",
    "        h2('This is a sub-header', style='k:v'),\n",
    "    ], _class='foo')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d644f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```xml\n",
       "<html>\n",
       "  <p>This is a paragraph</p>\n",
       "  <hr />\n",
       "  <x-custom foo=\"bar\" />\n",
       "  <img src=\"http://example.prg\" />\n",
       "  <div class=\"foo\">\n",
       "    <h1>This is a header</h1>\n",
       "    <h2 style=\"k:v\">This is a sub-header</h2>\n",
       "  </div>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_xml(a, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def json_to_xml(d:dict, rnm:str)->str:\n",
    "    \"Convert `d` to XML with root name `rnm`.\"\n",
    "    root = ET.Element(rnm)\n",
    "    def build_xml(data, parent):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))\n",
    "        elif isinstance(data, list):\n",
    "            for item in data: build_xml(item, ET.SubElement(parent, 'item'))\n",
    "        else: parent.text = str(data)\n",
    "    build_xml(d, root)\n",
    "    ET.indent(root)\n",
    "    return ET.tostring(root, encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4da1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<person>\n",
      "  <surname>Howard</surname>\n",
      "  <firstnames>\n",
      "    <item>Jeremy</item>\n",
      "    <item>Peter</item>\n",
      "  </firstnames>\n",
      "  <address>\n",
      "    <state>Queensland</state>\n",
      "    <country>Australia</country>\n",
      "  </address>\n",
      "</person>\n"
     ]
    }
   ],
   "source": [
    "a = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n",
    "         address=dict(state='Queensland',country='Australia'))\n",
    "print(json_to_xml(a, 'person'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
